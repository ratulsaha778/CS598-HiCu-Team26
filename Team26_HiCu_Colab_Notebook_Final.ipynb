{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blackhat-93/HiCu-Reproduce/blob/dryrun_colab/Colab_Cuong.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZ7rA3If7lqg"
      },
      "source": [
        "# **Project Title: HiCu-ICD (Project ID 17) - Final Project Report for CS598 DL4H – Spring 2024**\n",
        "***\n",
        "* Project Team ID: **26**\n",
        "* Team Members: Ratul Saha (**ratuls2 / ratuls2@illinois.edu**)\n",
        "* Github Repo Link: https://github.com/ratulsaha778/CS598-HiCu-Team26/\n",
        "* Notebook:\n",
        "    1. Colab: https://colab.research.google.com/drive/1YC4kPrZb5atKXLMuw4kRxDUKjJSl9mvT?usp=sharing\n",
        "    2.   Github: https://github.com/ratulsaha778/CS598-HiCu-Team26/blob/main/Team26_HiCu_Colab_Notebook_Draft.ipynb\n",
        "\n",
        "* Google Drive link: https://drive.google.com/drive/folders/1wb8_7s_7mVQpuYbco3Em38hf8mxTk7kX?usp=sharing\n",
        "* Presentation Video: TBD (youtube)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfhrkPWr-hVE"
      },
      "source": [
        "# **Introduction**\n",
        "***\n",
        "The project, titled **“HiCu-ICD”, is based on the MLHC 2022 paper \"HiCu: Leveraging Hierarchy for Curriculum Learning in Automated ICD Coding\"**. HiCu, or Hierarchical Curriculum Learning, improves ICD coding accuracy by leveraging the hierarchy of ICD codes, which groups diagnosis codes based on various organ systems in the human body.\n",
        "\n",
        "Proceedings of Machine Learning Research 182:1–25, 2022\n",
        "HiCu: Leveraging hierarchy for curriculum learning in automated ICD coding.\n",
        "W Ren, R Zeng, T Wu, T Zhu, RG Krishnan\n",
        "Machine Learning for Healthcare Conference, 198-223\n",
        "\n",
        "Google Scholar Link: https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sc_rpHcAAAAJ&citation_for_view=sc_rpHcAAAAJ:u-x6o8ySG0sC\n",
        "\n",
        "Weiming Ren wren@cs.toronto.edu, Ruijing Zeng jackzeng@cs.toronto.edu, Tongzi Wu tongziwu@cs.toronto.edu, Tianshu Zhu tianshu@cs.toronto.edu, Rahul G. Krishnan rahulgk@cs.toronto.edu (Department of Computer Science, University of Toronto & the Vector Institute, Toronto, Ontario, Canada)\n",
        "\n",
        "Original Code repository: https://github.com/wren93/HiCu-ICD.\n",
        "\n",
        "ICD codes are global standardized codes that are used for coding various diagnoses, symptoms, and procedures documented in healthcare settings. They are integral to managing patient care, conducting epidemiological studies, and facilitating healthcare billing. The automation of ICD coding is aimed at improving efficiency and reducing the potential for errors in medical documentation.\n",
        "\n",
        "Improving clinician throughput is an important technological opportunity for supporting improved healthcare services. When clinicians write notes, a smart process would be beneficial which can document correct diagnosis codes against the human notes. Mapping the long and detailed clinical notes and discharge summaries buried under patient profiles (Electronic Health Records / EHR) to specific ICD (International Classification of Diseases) coding - is a time-consuming, error-prone, and challenging task due to many possible codes and the complex relationships between them. The original paper aims to address the problem of automated coding of medical diagnoses and procedures using the International Classification of Diseases (ICD) system. The paper proposes a novel hierarchical curriculum learning approach that leverages the hierarchical structure of the ICD codes to improve the accuracy and efficiency of automated ICD coding.\n",
        "\n",
        "The paper uses a hierarchical structure of ICD codes to train the model in a curriculum learning framework. The approach involves learning simpler codes before more complex codes, designed based on the hierarchical structure of the ICD codes. It takes advantage of the hierarchical structure of the ICD codes to improve the model's ability to learn complex relationships between the codes, which is difficult to achieve using traditional flat learning approaches.\n",
        "\n",
        "Curriculum learning is the design of curricula i.e., in the sequential design of tasks that gradually increase in difficulty. HiCu is an innovation over this process that can predict ICD codes from the natural language descriptions of the patients. It leverages the hierarchy of ICD codes which is grouped based on various organ systems of the human body. The HiCu algorithm uses the graph structure in the space of outputs to design curricula for multi-label classification.\n",
        "\n",
        "The algorithm is based on:\n",
        "\n",
        "*   The Tree structure: The decision boundaries for different ICD codes are not independent. The ICD codes are organized in a tree structure which defines a notion of similarity between codes. This means that dissimilar labels will have different ancestors in the tree and vice versa. As I go deeper into each sub-tree, the specificity of the codes increases. This means that HiCu can provide wider and non-overlapping decision boundaries for multi-label classification as the diseases and organs are grouped under defined boundaries.\n",
        "*   HiCu explicitly incorporates techniques to handle label imbalance. This is essential to ensure parity of performance of predictive models on both rare and frequent labels. HiCu can predict rare and frequent labels with equal accuracy.\n",
        "\n",
        "HiCu is an improvement over curriculum learning which is used in medical code prediction using graph structure for solving multi-label classification problem.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2Bg6kHf-fAQ"
      },
      "source": [
        "# **Scope of Reproducibility**\n",
        "***\n",
        "ICD codes follow a logical grouping by following a hierarchy of disease, symptoms and body parts. The grouping helps form an ordered tree structure. The HiCu algorithm is inspired from this graph structure which is used to design curricula for multi-label classification. The hierarchical curricula learning claims to provide wider and non-overlapping decision boundary for multi-label classification as the disease and organs are grouped under defined boundaries. ICD codes are organized in a tree structure which establishes similarity, in other words dissimilar labels will have different ancestors in the tree.\n",
        "\n",
        "As addressed in the original paper, below claims would be validated through reproduction of the model performance results:\n",
        "***\n",
        "* **Claim 1**: HiCuA (Hyperbolic Correction Addition) significantly enhances the MultiResCNN model's performance (improved AUC and F1 scores).\n",
        "* **Claim 2**: Heirarchical learning model using the graph structure is better than the non-heirarchical representation of ICD codes (degrading AUC and F1 scores).\n",
        "***\n",
        "As part of the project draft, the model was trained on MultiResCNN over ‘train_full.csv’ data with embed file ‘processed_full_100.embed’, Asymmetric loss function, and ‘HierarchicalHyperbolic’ decoder.\n",
        "\n",
        "The final project report highlights model performance against the original project claims.\n",
        "I ran MultiResCNN with HiCuA. Below programs were used:\n",
        "* run_multirescnn_50.py\n",
        "* run_multirescnn_hicua_50.py\n",
        "* run_multirescnn_hicua_asl_50.py\n",
        "* run_multirescnn_hicua_asl_full.py\n",
        "* run_multirescnn_hicuc_50.py\n",
        "* run_multirescnn_hicuc_asl_50.py\n",
        "\n",
        "I could not run RAC with HiCuA (below programs) due to resource constraints on Google Colab Pro.\n",
        "* run_rac_hicua_full.py\n",
        "* run_rac_50.py\n",
        "* run_rac_full.py\n",
        "\n",
        "I kept the LAAT model training out-of-scope for my experiments.\n",
        "\n",
        "When these programs were run with GPU, I configured the GPU parameter in the code and also updating **parser.add_argument(\"--gpu\"** parameter in **‘/utils/options.py’** file.\n",
        "In Google Colab, the programs were run through code snippet:\n",
        "\n",
        "**!python /content/HiCu-ICD-Team26-Spring24/runs/run_multirescnn_hicua_50.py**\n",
        "\n",
        "In local Windows computer, the programs were run through command line:\n",
        "\n",
        "**python /runs/run_multirescnn_hicua_50.py**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMafjAer-4_x"
      },
      "source": [
        "# **Methodology**\n",
        "***\n",
        "This project aims at improving the ICD classification process. It leverages a hierarchical structure for curriculum learning to improve the accuracy and efficiency of automated ICD coding. It uses the MIMIC-III dataset for model training and evaluation.\n",
        "\n",
        "The primary objective of this project is to design curricula for multi-label classification models that predict ICD diagnosis and procedure codes from natural language descriptions of patients. The project uses the MIMIC-III dataset for model training and evaluation. The data preprocessing code from MultiResCNN is used to set up the dataset. The project proposes Hierarchical Curriculum Learning (HiCu), an algorithm that uses graph structure in the space of outputs to design curricula for multi-label classification.\n",
        "\n",
        "Pre-processing was done in local Windows 11 computer. Model training and performance check was done in Google Colab. However I observed, even with Google Colab 1 Tesla T4 GPU, the model training was very slow.\n",
        "\n",
        "### **Environment**\n",
        "Team predominantly used Google Colab as the primary platform to train the models. Google Colab with and without GPU was used based on timing and resource availability. Google Colab Pro was used at times to run the model training faster with the help of a GPU.\n",
        "At the same time, parallel model trainings sessions were run at local MS Windows 11 computer.\n",
        "\n",
        "Local windows computer was configured through Anaconda.\n",
        "Original project used **\"requirements.txt\"** file to setup the environment. It didn't work due to Python and packages’ version difference. I used **\"environment.yml\"** file to configure.\n",
        "Command to configure the environment: conda env create -f environment.yml\n",
        "\n",
        "Google Colab with GPU configuration:\n",
        "* python: 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n",
        "* gensim: 4.3.2\n",
        "* nltk: 3.8.1\n",
        "* numpy: 1.25.2\n",
        "* pandas: 2.0.3\n",
        "* scikit-learn: 1.2.2\n",
        "* scipy: 1.11.4\n",
        "* tqdm: 4.66.2\n",
        "* transformers: 4.40.1\n",
        "* packaging: 24.0\n",
        "* torch: 2.2.1+cu121\n",
        "* GPU: Tesla T4. NVIDIA-SMI 535.104.05. Driver Version: 535.104.05\n",
        "* CUDA Version: 12.2\n",
        "* High-RAM runtime with 54.8 gigabytes of available RAM\n",
        "* Number of CPU cores: 8\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fm-JHIP8_CBZ"
      },
      "source": [
        "### **Data**\n",
        "The dataset MIMIC-III v1.4 (mimic 3) was downloaded from https://physionet.org/content/mimiciii/1.4/ which was first published 2nd Sept 2016 with the intent of enhancing data quality and providing a large amount of additional data for Metavision patients.\n",
        "\n",
        "Resource citations:\n",
        "Johnson, A., Pollard, T., & Mark, R. (2016). MIMIC-III Clinical Database (version 1.4). PhysioNet. https://doi.org/10.13026/C2XW26.\n",
        "\n",
        "Original publication:\n",
        "Johnson, A. E. W., Pollard, T. J., Shen, L., Lehman, L. H., Feng, M., Ghassemi, M., Moody, B., Szolovits, P., Celi, L. A., & Mark, R. G. (2016). MIMIC-III, a freely accessible critical care database. Scientific Data, 3, 160035.\n",
        "\n",
        "Citation for PhysioNet:\n",
        "Goldberger, A., Amaral, L., Glass, L., Hausdorff, J., Ivanov, P. C., Mark, R., ... & Stanley, H. E. (2000). PhysioBank, PhysioToolkit, and PhysioNet: Components of a new research resource for complex physiologic signals. Circulation [Online]. 101 (23), pp. e215–e220.\n",
        "\n",
        "MIMIC contains detailed information regarding the clinical care of patients. In order to obtain access, it is necessary to finish the MIMIC CITI program training provided by MIT and get the certificate.\n",
        "\n",
        "* From the website https://www.citiprogram.org/index.cfm?pageID=154&icat=0&ac=0 : Under Register, I needed to use “Massachusetts Institute of Technology Affiliate” as the organization affiliation (not “independent learner”) and create an account with UIUC email.\n",
        "* Then navigated to Massachusetts Institute of Technology Affiliates course. In the Human Subjects training category, I chose \"Data or Specimens Only Research\" course.\\\n",
        "* I completed the course and got both certificate and report.\n",
        "* I applied access at PhysioNet: https://eicu-crd.mit.edu/gettingstarted/access/ with UIUC email. Prof. Jimeng Sun and the course (CS 598 Deep Learning for Healthcare at UIUC) was mentioned in the application. Training report was uploaded as certification verification. The actual certificate was not used.\n",
        "\n",
        "After the application was approved, I downloaded the dataset from the protected website as single large 6.2GB zip file. Over slower internet, it is advisable to download the individual zipped files and unzip them with any unzip / untar tool. I did not have any tool installed in Windows, so I used a python program to unzip them.\n",
        "\n",
        "This dataset provides a collection of comma-separated value (CSV) files. Each data file has its own identifiers, suffixed with ‘ID’. E.g., SUBJECT_ID is assigned to a unique patient, HADM_ID refers to a unique admission, ICUSTAY_ID relates to a unique visit to ICU. Events such as notes, laboratory tests, and fluid balance are stored in a series of ‘events’ data files. E.g., OUTPUTEVENTS contains all measurements related to output for a given patient, while LABEVENTS contains laboratory test results for a patient. Data files prefixed with ‘D_’ are dictionaries and contain definitions for identifiers. Rows in CHARTEVENTS linked to a single ITEMID represent the measured concept, but actual name of the measurement is not present in this file. When CHARTEVENTS and D_ITEMS are joined by ITEMID, the details emerge."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9wEDnU2_sT3"
      },
      "source": [
        "The data files used are placed under ‘data’ folder in project root folder in Google Drive.\n",
        "\n",
        "*data*\n",
        "*   D_ICD_DIAGNOSES.csv\n",
        "*   D_ICD_PROCEDURES.csv\n",
        "*   mimic3/PROCEDURES_ICD.csv\n",
        "*   mimic3/DIAGNOSES_ICD.csv\n",
        "*   mimic3/NOTEEVENTS.csv *italicized text*\n",
        "\n",
        "Supplementary *_hadm_ids.csv files, which contain unique identifiers for hospital admissions, are utilized to ensure that the data for analysis precisely corresponds to specific patient stays. This facilitates accurate matching of clinical notes to their respective admissions, crucial for the integrity of the data used in our experiments.\n",
        "\n",
        "HADM files were downloaded from https://github.com/jamesmullenbach/caml-mimic/tree/master/mimicdata/mimic3. They are also loaded into Google Drive under mimic3 folder.\n",
        "\n",
        "*   dev_50_hadm_ids.csv\n",
        "*   dev_full_hadm_ids.csv\n",
        "*   test_50_hadm_ids.csv\n",
        "*   test_full_hadm_ids.csv\n",
        "*   train_50_hadm_ids.csv\n",
        "*   train_full_hadm_ids.csv\n",
        "\n",
        "Together, these resources ensure a comprehensive dataset that supports the experimental replication and validation of the selected hypotheses stated in the original study.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeySOj_pASSW"
      },
      "source": [
        "***\n",
        "**Some statistics about the source data**:\n",
        "*   50K+ patients, including their clinical notes and their corresponding ICD codes.\n",
        "*   8994 unique ICD-9 codes.\n",
        "*   The experiment used top 50 codes with a subset of 11,317 summaries for training, validation and testing.\n",
        "*   The full dataset has 47,719 training summaries, 1,631 validation summaries and 3,372 testing summaries.\n",
        "* Notes data has 2,083,180 clinical notes with 92,868,012 tokens.\n",
        "* 52,726 unique hospital admissions (HADM_ID) and 41,127 unique subjects (SUBJECT_ID).\n",
        "\n",
        "***\n",
        "\n",
        "HiCu algorithm has 2 processes.\n",
        "*   **Pre-processing**: raw files are read, and intermediate files are created.\n",
        "*   **Post-processing**: the model is trained on the intermediate files.\n",
        "\n",
        "All these data files were preprocessed through a python script ‘preprocess_mimic3.py’.\n",
        "The script is executed by running the below command:\n",
        "\n",
        "`python preprocess_mimic3.py`\n",
        "\n",
        "Pre-processing step needed many Python libraries: genism, nltk, numpy, pandas, scikit_learn, scipy, torch, tqdm, transformers, utils.\n",
        "The inputs csv files were read from the ‘data’ folder and ‘mimic3’ sub-folder under ‘data’, under the project root folder. The output files were saved under ‘mimic3’ sub-folder.\n",
        "\n",
        "The pre-processing **concatenates** clinical notes with their corresponding ICD codes and filtering operations to align medical records correctly. This ensures that each clinical note is accurately associated with the correct medical coding. It **removes Rare Terms** during vocabulary building. It lowers the total vocabulary to 51,919 terms from starting 140,796. This step is important for focusing the model's training on relevant terms and avoiding overfitting on noise. The dataset was **split into training, development, and testing sets** for training models.\n",
        "\n",
        "Below are the high-level steps from the pre-processing program (**preprocess_mimic3.py**):\n",
        "```\n",
        "1.  process code-related files\n",
        "2.  process notes\n",
        "3.  filter out the codes that not emerge in notes\n",
        "4.  link notes with their code\n",
        "5.  statistic unique word, total word, HADM_ID number\n",
        "6.  split data into train dev test\n",
        "7.  sort data by its note length, add length to the last column\n",
        "8.  train word embeddings via word2vec and fasttext\n",
        "9.  statistic the top 50 code\n",
        "10. split data according to train_50_hadm_ids dev and test\n",
        "11. sort data by its note length, add length to the last column\n",
        "12. create vocab for the models\n",
        "```\n",
        "Pre-processing was performed in local Windows computer. Then the processed datasets were loaded into Google Drive. Which then were used in Google Colab during training.\n",
        "\n",
        "The pre-processing step, for MultiResCNN and RAC models, generates some CSV files (top 50 codes, full set of codes, vocabulary for both models) and processed full 100 and 300 embed files. These files were loaded into Google Drive. While working on the Python Notebook in Google Colab Pro, these files were referenced by mounting Google Drive in Colab.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJe6t81qAu3q"
      },
      "source": [
        "### **Model**\n",
        "> Citation of the Original Paper:\n",
        "\n",
        "Proceedings of Machine Learning Research 182:1–25, 2022 HiCu: Leveraging hierarchy for curriculum learning in automated ICD coding. W Ren, R Zeng, T Wu, T Zhu, RG Krishnan Machine Learning for Healthcare Conference, 198-223\n",
        "\n",
        "Google Scholar Link: https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sc_rpHcAAAAJ&citation_for_view=sc_rpHcAAAAJ:u-x6o8ySG0sC\n",
        "\n",
        "Weiming Ren wren@cs.toronto.edu, Ruijing Zeng jackzeng@cs.toronto.edu, Tongzi Wu tongziwu@cs.toronto.edu, Tianshu Zhu tianshu@cs.toronto.edu, Rahul G. Krishnan rahulgk@cs.toronto.edu (Department of Computer Science, University of Toronto & the Vector Institute, Toronto, Ontario, Canada).\n",
        "\n",
        "\n",
        "> Original Code repository: https://github.com/wren93/HiCu-ICD.\n",
        "\n",
        "The Curriculum Learning algorithm is described below.\n",
        "\n",
        "The original paper uses the Poincare model using hyperbolic embeddings. The HiCu architecture consists of an encoder-decoder framework combined with a hierarchical curriculum learning algorithm. The model is first trained on labels at the first level of the label tree using level one decoder, and then proceeds to level two using the knowledge transfer mechanism. This process is repeated until the model reaches the final level in the label tree.\n",
        "\n",
        "During training at each level, the hyperbolic embeddings of the ICD codes are used to guide the attention computation in the decoder. The hyperbolic embeddings allow the model to learn a representation of the ICD code hierarchy that is more structured and aligned with the hierarchical structure of the codes. The model was run the original HiCu algorithm with high-order grouping of ICD code blocks to create a two-level hierarchy and is trained on the mimic3/train_full.csv dataset to verify its performance.\n",
        "\n",
        "The model defined in the code includes several classes representing different neural network architectures for automated ICD coding. These models include configurations for handling multi-label classification with a focus on curriculum learning and label hierarchies.\n",
        "\n",
        "#### **Model Architecture**:\n",
        "* **WordRep** (Word Representation):\n",
        "  * Embedding Layer: Utilizes pretrained embeddings with a dimension depending on the pretrained file, or initializes a new embedding layer if no pretrained file is provided. The embedding size can be 100, 300, etc., based on the available data.\n",
        "  * Dropout: Applied after the embedding layer to prevent overfitting, with a dropout rate of 0.1 as configured in the model settings. This helps improve the model's generalization capability on unseen data.\n",
        "\n",
        "* **Decoders**:\n",
        "  * RandomlyInitializedDecoder, RACDecoder, LAATDecoder, Decoder: Each uses an attention mechanism tailored to the needs of hierarchical ICD code prediction.\n",
        "    * Attention Units: Typically involves layers with dimensions tuned to the size of the dataset labels (e.g., number of ICD codes).\n",
        "    * Activation Function: Uses Tanh or ReLU in intermediate layers to introduce non-linearity.\n",
        "    * Hyperbolic Embedding Layers: Specific to HiCuA strategies, embedding sizes match the hyperbolic space dimensions used (commonly around 50 dimensions).\n",
        "\n",
        "* **MultiResCNN**:\n",
        "  * Convolutional Layers: Multiple convolutional layers with filter sizes that may vary from small (3-5 words) to large (7-9 words) to capture different levels of textual granularity.\n",
        "  * Residual Connections: Helps in flowing gradients and avoiding the vanishing gradient problem in deep networks.\n",
        "  * Activation Function: Uses Tanh activation functions following convolutional layers to add non-linearity.\n",
        "\n",
        "* **LongformerClassifier**:\n",
        "  * Longformer Layers: Uses a Longformer architecture, suitable for processing long text sequences with attention mechanisms that focus on different parts of the input sequence efficiently.\n",
        "  * Configuration: Configured with parameters such as number of attention heads, hidden dimensions (typically 768 for base models), and specific attention window sizes.\n",
        "\n",
        "The model implementation code is present in **/utils/models.py** file.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Training Code Implementation\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.init import xavier_uniform_ as xavier_uniform\n",
        "import numpy as np\n",
        "from utils.utils import build_pretrain_embedding, load_embeddings\n",
        "from utils.losses import AsymmetricLoss, AsymmetricLossOptimized\n",
        "from math import floor, sqrt\n",
        "\n",
        "\n",
        "class WordRep(nn.Module):\n",
        "    def __init__(self, args, Y, dicts):\n",
        "        super(WordRep, self).__init__()\n",
        "\n",
        "        if args.embed_file:\n",
        "            print(\"loading pretrained embeddings from {}\".format(args.embed_file))\n",
        "            if args.use_ext_emb:\n",
        "                pretrain_word_embedding, pretrain_emb_dim = build_pretrain_embedding(args.embed_file, dicts['w2ind'],\n",
        "                                                                                     True)\n",
        "                W = torch.from_numpy(pretrain_word_embedding)\n",
        "            else:\n",
        "                W = torch.Tensor(load_embeddings(args.embed_file))\n",
        "\n",
        "            self.embed = nn.Embedding(W.size()[0], W.size()[1], padding_idx=0)\n",
        "            self.embed.weight.data = W.clone()\n",
        "        else:\n",
        "            # add 2 to include UNK and PAD\n",
        "            self.embed = nn.Embedding(len(dicts['w2ind']) + 2, args.embed_size, padding_idx=0)\n",
        "        self.feature_size = self.embed.embedding_dim\n",
        "\n",
        "        self.embed_drop = nn.Dropout(p=args.dropout)\n",
        "\n",
        "        self.conv_dict = {1: [self.feature_size, args.num_filter_maps],\n",
        "                     2: [self.feature_size, 100, args.num_filter_maps],\n",
        "                     3: [self.feature_size, 150, 100, args.num_filter_maps],\n",
        "                     4: [self.feature_size, 200, 150, 100, args.num_filter_maps]\n",
        "                     }\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = [self.embed(x)]\n",
        "\n",
        "        x = torch.cat(features, dim=2)\n",
        "\n",
        "        x = self.embed_drop(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class RandomlyInitializedDecoder(nn.Module):\n",
        "    \"\"\"\n",
        "    The original per-label attention network: query matrix is randomly initialized\n",
        "    \"\"\"\n",
        "    def __init__(self, args, Y, dicts, input_size):\n",
        "        super(RandomlyInitializedDecoder, self).__init__()\n",
        "\n",
        "        Y = Y[-1]\n",
        "\n",
        "        self.U = nn.Linear(input_size, Y)\n",
        "        xavier_uniform(self.U.weight)\n",
        "\n",
        "\n",
        "        self.final = nn.Linear(input_size, Y)\n",
        "        xavier_uniform(self.final.weight)\n",
        "\n",
        "        self.loss_function = nn.BCEWithLogitsLoss()\n",
        "\n",
        "\n",
        "    def forward(self, x, target, text_inputs):\n",
        "        # attention\n",
        "        alpha = F.softmax(self.U.weight.matmul(x.transpose(1, 2)), dim=2)\n",
        "\n",
        "        m = alpha.matmul(x)\n",
        "\n",
        "        y = self.final.weight.mul(m).sum(dim=2).add(self.final.bias)\n",
        "\n",
        "        loss = self.loss_function(y, target)\n",
        "        return y, loss, alpha, m\n",
        "\n",
        "    def change_depth(self, depth=0):\n",
        "        # placeholder\n",
        "        pass\n",
        "\n",
        "\n",
        "class RACDecoder(nn.Module):\n",
        "    \"\"\"\n",
        "    The decoder proposed by Kim et al. (Code title-guided attention)\n",
        "    \"\"\"\n",
        "    def __init__(self, args, Y, dicts, input_size):\n",
        "        super(RACDecoder, self).__init__()\n",
        "\n",
        "        Y = Y[-1]\n",
        "\n",
        "        self.input_size = input_size\n",
        "\n",
        "        self.register_buffer(\"c2title\", torch.LongTensor(dicts[\"c2title\"]))\n",
        "        self.word_rep = WordRep(args, Y, dicts)\n",
        "\n",
        "        filter_size = int(args.code_title_filter_size)\n",
        "        self.code_title_conv = nn.Conv1d(self.word_rep.feature_size, input_size,\n",
        "                                         filter_size, padding=int(floor(filter_size / 2)))\n",
        "        xavier_uniform(self.code_title_conv.weight)\n",
        "        self.code_title_maxpool = nn.MaxPool1d(args.num_code_title_tokens)\n",
        "\n",
        "        self.final = nn.Linear(input_size, Y)\n",
        "        xavier_uniform(self.final.weight)\n",
        "\n",
        "        self.loss_function = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def forward(self, x, target, text_inputs):\n",
        "        code_title = self.word_rep(self._buffers['c2title']).transpose(1, 2)\n",
        "        # attention\n",
        "        U = self.code_title_conv(code_title)\n",
        "        U = self.code_title_maxpool(U).squeeze(-1)\n",
        "        U = torch.tanh(U)\n",
        "\n",
        "        attention_score = U.matmul(x.transpose(1, 2)) / sqrt(self.input_size)\n",
        "        alpha = F.softmax(attention_score, dim=2)\n",
        "\n",
        "        m = alpha.matmul(x)\n",
        "\n",
        "        y = self.final.weight.mul(m).sum(dim=2).add(self.final.bias)\n",
        "\n",
        "        loss = self.loss_function(y, target)\n",
        "        return y, loss, alpha, m\n",
        "\n",
        "    def change_depth(self, depth=0):\n",
        "        # placeholder\n",
        "        pass\n",
        "\n",
        "\n",
        "class LAATDecoder(nn.Module):\n",
        "    def __init__(self, args, Y, dicts, input_size):\n",
        "        super(LAATDecoder, self).__init__()\n",
        "\n",
        "        Y = Y[-1]\n",
        "\n",
        "        self.attn_dim = args.attn_dim\n",
        "        self.W = nn.Linear(input_size, self.attn_dim)\n",
        "        self.U = nn.Linear(self.attn_dim, Y)\n",
        "        xavier_uniform(self.W.weight)\n",
        "        xavier_uniform(self.U.weight)\n",
        "\n",
        "        self.final = nn.Linear(input_size, Y)\n",
        "        xavier_uniform(self.final.weight)\n",
        "\n",
        "        self.loss_function = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def forward(self, x, target, text_inputs):\n",
        "        z = torch.tanh(self.W(x))\n",
        "        # attention\n",
        "        alpha = F.softmax(self.U.weight.matmul(z.transpose(1, 2)), dim=2)\n",
        "\n",
        "        m = alpha.matmul(x)\n",
        "\n",
        "        y = self.final.weight.mul(m).sum(dim=2).add(self.final.bias)\n",
        "\n",
        "        loss = self.loss_function(y, target)\n",
        "        return y, loss, alpha, m\n",
        "\n",
        "    def change_depth(self, depth=0):\n",
        "        # placeholder\n",
        "        pass\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Decoder: knowledge transfer initialization and hyperbolic embedding correction\n",
        "    \"\"\"\n",
        "    def __init__(self, args, Y, dicts, input_size):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.dicts = dicts\n",
        "\n",
        "        self.decoder_dict = nn.ModuleDict()\n",
        "        for i in range(len(Y)):\n",
        "            y = Y[i]\n",
        "            self.decoder_dict[str(i) + '_' + '0'] = nn.Linear(input_size, y)\n",
        "            self.decoder_dict[str(i) + '_' + '1'] = nn.Linear(input_size, y)\n",
        "            xavier_uniform(self.decoder_dict[str(i) + '_' + '0'].weight)\n",
        "            xavier_uniform(self.decoder_dict[str(i) + '_' + '1'].weight)\n",
        "\n",
        "        self.use_hyperbolic =  args.decoder.find(\"Hyperbolic\") != -1\n",
        "        if self.use_hyperbolic:\n",
        "            self.cat_hyperbolic = args.cat_hyperbolic\n",
        "            if not self.cat_hyperbolic:\n",
        "                self.hyperbolic_fc_dict = nn.ModuleDict()\n",
        "                for i in range(len(Y)):\n",
        "                    self.hyperbolic_fc_dict[str(i)] = nn.Linear(args.hyperbolic_dim, input_size)\n",
        "            else:\n",
        "                self.query_fc_dict = nn.ModuleDict()\n",
        "                for i in range(len(Y)):\n",
        "                    self.query_fc_dict[str(i)] = nn.Linear(input_size + args.hyperbolic_dim, input_size)\n",
        "\n",
        "            # build hyperbolic embedding matrix\n",
        "            self.hyperbolic_emb_dict = {}\n",
        "            for i in range(len(Y)):\n",
        "                self.hyperbolic_emb_dict[i] = np.zeros((Y[i], args.hyperbolic_dim))\n",
        "                for idx, code in dicts['ind2c'][i].items():\n",
        "                    self.hyperbolic_emb_dict[i][idx, :] = np.copy(dicts['poincare_embeddings'].get_vector(code))\n",
        "                self.register_buffer(name='hb_emb_' + str(i), tensor=torch.tensor(self.hyperbolic_emb_dict[i], dtype=torch.float32))\n",
        "\n",
        "        self.cur_depth = 5 - args.depth\n",
        "        self.is_init = False\n",
        "        self.change_depth(self.cur_depth)\n",
        "\n",
        "        if args.loss == 'BCE':\n",
        "            self.loss_function = nn.BCEWithLogitsLoss()\n",
        "        elif args.loss == 'ASL':\n",
        "            asl_config = [float(c) for c in args.asl_config.split(',')]\n",
        "            self.loss_function = AsymmetricLoss(gamma_neg=asl_config[0], gamma_pos=asl_config[1],\n",
        "                                                clip=asl_config[2], reduction=args.asl_reduction)\n",
        "        elif args.loss == 'ASLO':\n",
        "            asl_config = [float(c) for c in args.asl_config.split(',')]\n",
        "            self.loss_function = AsymmetricLossOptimized(gamma_neg=asl_config[0], gamma_pos=asl_config[1],\n",
        "                                                         clip=asl_config[2], reduction=args.asl_reduction)\n",
        "\n",
        "    def change_depth(self, depth=0):\n",
        "        if self.is_init:\n",
        "            # copy previous attention weights to current attention network based on ICD hierarchy\n",
        "            ind2c = self.dicts['ind2c']\n",
        "            c2ind = self.dicts['c2ind']\n",
        "            hierarchy_dist = self.dicts['hierarchy_dist']\n",
        "            for i, code in ind2c[depth].items():\n",
        "                tree = hierarchy_dist[depth][code]\n",
        "                pre_idx = c2ind[depth - 1][tree[depth - 1]]\n",
        "\n",
        "                self.decoder_dict[str(depth) + '_' + '0'].weight.data[i, :] = self.decoder_dict[str(depth - 1) + '_' + '0'].weight.data[pre_idx, :].clone()\n",
        "                self.decoder_dict[str(depth) + '_' + '1'].weight.data[i, :] = self.decoder_dict[str(depth - 1) + '_' + '1'].weight.data[pre_idx, :].clone()\n",
        "\n",
        "        if not self.is_init:\n",
        "            self.is_init = True\n",
        "\n",
        "        self.cur_depth = depth\n",
        "\n",
        "    def forward(self, x, target, text_inputs):\n",
        "        # attention\n",
        "        if self.use_hyperbolic:\n",
        "            if not self.cat_hyperbolic:\n",
        "                query = self.decoder_dict[str(self.cur_depth) + '_' + '0'].weight + self.hyperbolic_fc_dict[str(self.cur_depth)](self._buffers['hb_emb_' + str(self.cur_depth)])\n",
        "            else:\n",
        "                query = torch.cat([self.decoder_dict[str(self.cur_depth) + '_' + '0'].weight, self._buffers['hb_emb_' + str(self.cur_depth)]], dim=1)\n",
        "                query = self.query_fc_dict[str(self.cur_depth)](query)\n",
        "        else:\n",
        "            query = self.decoder_dict[str(self.cur_depth) + '_' + '0'].weight\n",
        "\n",
        "        alpha = F.softmax(query.matmul(x.transpose(1, 2)), dim=2)\n",
        "        m = alpha.matmul(x)\n",
        "\n",
        "        y = self.decoder_dict[str(self.cur_depth) + '_' + '1'].weight.mul(m).sum(dim=2).add(self.decoder_dict[str(self.cur_depth) + '_' + '1'].bias)\n",
        "\n",
        "        loss = self.loss_function(y, target)\n",
        "\n",
        "        return y, loss, alpha, m\n",
        "\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, inchannel, outchannel, kernel_size, stride, use_res, dropout):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.left = nn.Sequential(\n",
        "            nn.Conv1d(inchannel, outchannel, kernel_size=kernel_size, stride=stride, padding=int(floor(kernel_size / 2)), bias=False),\n",
        "            nn.BatchNorm1d(outchannel),\n",
        "            nn.Tanh(),\n",
        "            nn.Conv1d(outchannel, outchannel, kernel_size=kernel_size, stride=1, padding=int(floor(kernel_size / 2)), bias=False),\n",
        "            nn.BatchNorm1d(outchannel)\n",
        "        )\n",
        "\n",
        "        self.use_res = use_res\n",
        "        if self.use_res:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                        nn.Conv1d(inchannel, outchannel, kernel_size=1, stride=stride, bias=False),\n",
        "                        nn.BatchNorm1d(outchannel)\n",
        "                    )\n",
        "\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.left(x)\n",
        "        if self.use_res:\n",
        "            out += self.shortcut(x)\n",
        "        out = torch.tanh(out)\n",
        "        out = self.dropout(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class MultiResCNN(nn.Module):\n",
        "\n",
        "    def __init__(self, args, Y, dicts):\n",
        "        super(MultiResCNN, self).__init__()\n",
        "\n",
        "        self.word_rep = WordRep(args, Y, dicts)\n",
        "\n",
        "        self.conv = nn.ModuleList()\n",
        "        filter_sizes = args.filter_size.split(',')\n",
        "\n",
        "        self.filter_num = len(filter_sizes)\n",
        "        for filter_size in filter_sizes:\n",
        "            filter_size = int(filter_size)\n",
        "            one_channel = nn.ModuleList()\n",
        "            tmp = nn.Conv1d(self.word_rep.feature_size, self.word_rep.feature_size, kernel_size=filter_size,\n",
        "                            padding=int(floor(filter_size / 2)))\n",
        "            xavier_uniform(tmp.weight)\n",
        "            one_channel.add_module('baseconv', tmp)\n",
        "\n",
        "            conv_dimension = self.word_rep.conv_dict[args.conv_layer]\n",
        "            for idx in range(args.conv_layer):\n",
        "                tmp = ResidualBlock(conv_dimension[idx], conv_dimension[idx + 1], filter_size, 1, True,\n",
        "                                    args.dropout)\n",
        "                one_channel.add_module('resconv-{}'.format(idx), tmp)\n",
        "\n",
        "            self.conv.add_module('channel-{}'.format(filter_size), one_channel)\n",
        "\n",
        "        if args.decoder == \"HierarchicalHyperbolic\" or args.decoder == \"Hierarchical\":\n",
        "            self.decoder = Decoder(args, Y, dicts, self.filter_num * args.num_filter_maps)\n",
        "        elif args.decoder == \"RandomlyInitialized\":\n",
        "            self.decoder = RandomlyInitializedDecoder(args, Y, dicts, self.filter_num * args.num_filter_maps)\n",
        "        elif args.decoder == \"CodeTitle\":\n",
        "            self.decoder = RACDecoder(args, Y, dicts, self.filter_num * args.num_filter_maps)\n",
        "        else:\n",
        "            raise RuntimeError(\"wrong decoder name\")\n",
        "\n",
        "        self.cur_depth = 5 - args.depth\n",
        "\n",
        "\n",
        "    def forward(self, x, target, text_inputs):\n",
        "        x = self.word_rep(x)\n",
        "\n",
        "        x = x.transpose(1, 2)\n",
        "\n",
        "        conv_result = []\n",
        "        for conv in self.conv:\n",
        "            tmp = x\n",
        "            for idx, md in enumerate(conv):\n",
        "                if idx == 0:\n",
        "                    tmp = torch.tanh(md(tmp))\n",
        "                else:\n",
        "                    tmp = md(tmp)\n",
        "            tmp = tmp.transpose(1, 2)\n",
        "            conv_result.append(tmp)\n",
        "        x = torch.cat(conv_result, dim=2)\n",
        "\n",
        "        y, loss, alpha, m = self.decoder(x, target, text_inputs)\n",
        "\n",
        "        return y, loss, alpha, m\n",
        "\n",
        "    def freeze_net(self):\n",
        "        for p in self.word_rep.embed.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "import os\n",
        "from transformers import LongformerModel, LongformerConfig\n",
        "class LongformerClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, args, Y, dicts):\n",
        "        super(LongformerClassifier, self).__init__()\n",
        "\n",
        "        if args.longformer_dir != '':\n",
        "            print(\"loading pretrained longformer from {}\".format(args.longformer_dir))\n",
        "            config_file = os.path.join(args.longformer_dir, 'config.json')\n",
        "            self.config = LongformerConfig.from_json_file(config_file)\n",
        "            print(\"Model config {}\".format(self.config))\n",
        "            self.longformer = LongformerModel.from_pretrained(args.longformer_dir, gradient_checkpointing=True)\n",
        "        else:\n",
        "            self.config = LongformerConfig(\n",
        "                attention_mode=\"longformer\",\n",
        "                attention_probs_dropout_prob=0.1,\n",
        "                attention_window=[\n",
        "                    512,\n",
        "                    512,\n",
        "                    512,\n",
        "                    512,\n",
        "                    512,\n",
        "                    512,\n",
        "                ],\n",
        "                bos_token_id=0,\n",
        "                eos_token_id=2,\n",
        "                gradient_checkpointing=False,\n",
        "                hidden_act=\"gelu\",\n",
        "                hidden_dropout_prob=0.1,\n",
        "                hidden_size=768,\n",
        "                ignore_attention_mask=False,\n",
        "                initializer_range=0.02,\n",
        "                intermediate_size=3072,\n",
        "                layer_norm_eps=1e-05,\n",
        "                max_position_embeddings=4098,\n",
        "                model_type=\"longformer\",\n",
        "                num_attention_heads=12,\n",
        "                num_hidden_layers=6,\n",
        "                pad_token_id=1,\n",
        "                sep_token_id=2,\n",
        "                type_vocab_size=1,\n",
        "                vocab_size=50265\n",
        "            )\n",
        "            self.longformer = LongformerModel(self.config)\n",
        "\n",
        "        # decoder\n",
        "        self.decoder = Decoder(args, Y, dicts, self.config.hidden_size)\n",
        "\n",
        "\n",
        "    def forward(self, input_ids, token_type_ids, attention_mask, target):\n",
        "        global_attention_mask = torch.zeros_like(input_ids)\n",
        "            # global attention on cls token\n",
        "            # global_attention_mask[:, 0] = 1 # this line should be commented if using decoder\n",
        "        longformer_output = self.longformer(\n",
        "            input_ids=input_ids,\n",
        "            token_type_ids=token_type_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            global_attention_mask=global_attention_mask,\n",
        "            return_dict=False\n",
        "        )\n",
        "\n",
        "        output = longformer_output[0]\n",
        "        y, loss, alpha, m = self.decoder(output, target, None)\n",
        "\n",
        "        return y, loss, alpha, m\n",
        "\n",
        "    def freeze_net(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "class RACReader(nn.Module):\n",
        "    def __init__(self, args, Y, dicts):\n",
        "        super(RACReader, self).__init__()\n",
        "\n",
        "        self.word_rep = WordRep(args, Y, dicts)\n",
        "        filter_size = int(args.filter_size)\n",
        "\n",
        "        self.conv = nn.ModuleList()\n",
        "        for i in range(args.reader_conv_num):\n",
        "            conv = nn.Conv1d(self.word_rep.feature_size, self.word_rep.feature_size, kernel_size=filter_size,\n",
        "                                padding=int(floor(filter_size / 2)))\n",
        "            xavier_uniform(conv.weight)\n",
        "            self.conv.add_module(f'conv_{i+1}', conv)\n",
        "\n",
        "        self.dropout = nn.Dropout(p=args.dropout)\n",
        "\n",
        "        self.trans = nn.ModuleList()\n",
        "        for i in range(args.reader_trans_num):\n",
        "            trans = nn.TransformerEncoderLayer(self.word_rep.feature_size, 1, args.trans_ff_dim, args.dropout, \"relu\")\n",
        "            self.trans.add_module(f'trans_{i+1}', trans)\n",
        "\n",
        "        if args.decoder == \"HierarchicalHyperbolic\" or args.decoder == \"Hierarchical\":\n",
        "            self.decoder = Decoder(args, Y, dicts, self.word_rep.feature_size)\n",
        "        elif args.decoder == \"RandomlyInitialized\":\n",
        "            self.decoder = RandomlyInitializedDecoder(args, Y, dicts, self.word_rep.feature_size)\n",
        "        elif args.decoder == \"CodeTitle\":\n",
        "            self.decoder = RACDecoder(args, Y, dicts, self.word_rep.feature_size)\n",
        "        else:\n",
        "            raise RuntimeError(\"wrong decoder name\")\n",
        "\n",
        "    def forward(self, x, target, text_inputs=None):\n",
        "        x = self.word_rep(x)\n",
        "\n",
        "        x = x.transpose(1, 2)\n",
        "\n",
        "        for conv in self.conv:\n",
        "            x = conv(x)\n",
        "\n",
        "        x = torch.tanh(x).permute(2, 0, 1)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        for trans in self.trans:\n",
        "            x = trans(x)\n",
        "\n",
        "        x = x.permute(1, 0, 2)\n",
        "\n",
        "        y, loss, alpha, m = self.decoder(x, target, text_inputs)\n",
        "\n",
        "        return y, loss, alpha, m\n",
        "\n",
        "    def freeze_net(self):\n",
        "        for p in self.word_rep.embed.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "class LAAT(nn.Module):\n",
        "    def __init__(self, args, Y, dicts):\n",
        "        super(LAAT, self).__init__()\n",
        "        self.word_rep = WordRep(args, Y, dicts)\n",
        "\n",
        "        self.hidden_dim = args.lstm_hidden_dim\n",
        "        self.biLSTM = nn.LSTM(\n",
        "            input_size=self.word_rep.feature_size,\n",
        "            hidden_size=self.hidden_dim,\n",
        "            batch_first=True,\n",
        "            dropout=args.dropout,\n",
        "            bidirectional=True\n",
        "        )\n",
        "\n",
        "        self.output_dim = 2 * self.hidden_dim\n",
        "        self.use_LAAT = False\n",
        "\n",
        "        self.attn_dim = args.attn_dim\n",
        "        self.decoder_name = args.decoder\n",
        "        if \"LAAT\" in args.decoder:\n",
        "            if args.decoder == \"LAATHierarchicalHyperbolic\" or args.decoder == \"LAATHierarchical\":\n",
        "                self.decoder_name = args.decoder[4:]\n",
        "            self.output_dim = self.attn_dim\n",
        "            self.use_LAAT = True\n",
        "            self.W = nn.Linear(2 * self.hidden_dim, self.attn_dim)\n",
        "\n",
        "        if self.decoder_name == \"HierarchicalHyperbolic\" or self.decoder_name == \"Hierarchical\":\n",
        "            self.decoder = Decoder(args, Y, dicts, self.output_dim)\n",
        "        elif self.decoder_name == \"RandomlyInitialized\":\n",
        "            self.decoder = RandomlyInitializedDecoder(args, Y, dicts, self.output_dim)\n",
        "        elif self.decoder_name == \"CodeTitle\":\n",
        "            self.decoder = RACDecoder(args, Y, dicts, self.output_dim)\n",
        "        elif self.decoder_name == \"LAATDecoder\":\n",
        "            self.decoder = RandomlyInitializedDecoder(args, Y, dicts, self.output_dim)\n",
        "        else:\n",
        "            raise RuntimeError(\"wrong decoder name\")\n",
        "\n",
        "\n",
        "\n",
        "        self.cur_depth = 5 - args.depth\n",
        "\n",
        "    def forward(self, x, target, text_inputs):\n",
        "        # lengths = (x > 0).sum(dim=1).cpu()\n",
        "        x = self.word_rep(x)  # [batch, length, input_size]\n",
        "\n",
        "        # x = pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)\n",
        "        x1 = self.biLSTM(x)[0]\n",
        "        # x1 = pad_packed_sequence(x1, batch_first=True)[0]\n",
        "\n",
        "        if self.use_LAAT:\n",
        "            x1 = torch.tanh(self.W(x1))\n",
        "\n",
        "        y, loss, alpha, m = self.decoder(x1, target, text_inputs)\n",
        "\n",
        "        return y, loss, alpha, m\n",
        "\n",
        "\n",
        "def pick_model(args, dicts):\n",
        "    ind2c = dicts['ind2c']\n",
        "    Y = [len(ind2c[i]) for i in range(5)] # total number of ICD codes\n",
        "    if args.model == 'MultiResCNN':\n",
        "        model = MultiResCNN(args, Y, dicts)\n",
        "    elif args.model == 'longformer':\n",
        "        model = LongformerClassifier(args, Y, dicts)\n",
        "    elif args.model == 'RACReader':\n",
        "        model = RACReader(args, Y, dicts)\n",
        "    elif args.model == 'LAAT':\n",
        "        model = LAAT(args, Y, dicts)\n",
        "    else:\n",
        "        raise RuntimeError(\"wrong model name\")\n",
        "\n",
        "    if args.test_model:\n",
        "        model.decoder.change_depth(4)\n",
        "        sd = torch.load(args.test_model)\n",
        "        model.load_state_dict(sd)\n",
        "    if args.tune_wordemb == False:\n",
        "        model.freeze_net()\n",
        "    if len(args.gpu_list) == 1 and args.gpu_list[0] != -1: # single card training\n",
        "        model.cuda()\n",
        "    elif len(args.gpu_list) > 1: # multi-card training\n",
        "        model = nn.DataParallel(model, device_ids=args.gpu_list)\n",
        "        model = model.to(f'cuda:{model.device_ids[0]}')\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "_ZOGsW9Lpw5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Loading Pre-trained model**\n",
        "Below code can be used to load MultiResCNN with HiCuA architecture, mostly intended for validation and analysis in interactive mode in Google Colab. Further optimization is recommended for better functioning and compatibility.\n",
        "\n",
        "The pre-trained model files (.pth) are referenced from **\"/models\"** folder.\n",
        "\n",
        "Similarly, RAC with HiCuA and LAAT with HiCuA + ASL can also be pre-trained separately and included in the template code for performance testing."
      ],
      "metadata": {
        "id": "riCAS-lQqUP9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "class WordRep(nn.Module):\n",
        "    def __init__(self, embed_file, vocab_size, embed_dim, dropout):\n",
        "        super(WordRep, self).__init__()\n",
        "        if embed_file:\n",
        "            embeddings = np.load(embed_file)\n",
        "            W = torch.from_numpy(embeddings).float()\n",
        "        else:\n",
        "            W = torch.randn(vocab_size, embed_dim)\n",
        "        self.embed = nn.Embedding.from_pretrained(W, freeze=False)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.dropout(self.embed(x))\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, dropout):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.left = nn.Sequential(\n",
        "            nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size, padding=kernel_size//2, bias=False),\n",
        "            nn.BatchNorm1d(out_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(out_channels, out_channels, kernel_size=kernel_size, padding=kernel_size//2, bias=False),\n",
        "            nn.BatchNorm1d(out_channels)\n",
        "        )\n",
        "        self.shortcut = nn.Sequential(\n",
        "            nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=1, bias=False),\n",
        "            nn.BatchNorm1d(out_channels)\n",
        "        )\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.left(x) + self.shortcut(x)\n",
        "        return self.dropout(out)\n",
        "\n",
        "class MultiResCNN(nn.Module):\n",
        "    def __init__(self, embed_file, vocab_size, embed_size, num_filters, kernel_sizes, dropout):\n",
        "        super(MultiResCNN, self).__init__()\n",
        "        self.word_rep = WordRep(embed_file, vocab_size, embed_size, dropout)\n",
        "        self.conv = nn.ModuleList()\n",
        "        for size in kernel_sizes:\n",
        "            self.conv.append(ResidualBlock(embed_size, num_filters, size, dropout))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.word_rep(x).transpose(1, 2)\n",
        "        for conv in self.conv:\n",
        "            x = conv(x)\n",
        "        return x\n",
        "\n",
        "def load_model(model_path, embed_file, vocab_size, embed_size, num_filters, kernel_sizes, dropout):\n",
        "    model = MultiResCNN(embed_file, vocab_size, embed_size, num_filters, kernel_sizes, dropout)\n",
        "    # model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "# Specify paths and parameters\n",
        "model_path = '/content/HiCu-ICD-Team26-Spring24/models/MultiResCNN_HICUA.pth'\n",
        "embed_file = '/content/HiCu-ICD-Team26-Spring24/data/mimic3/processed_full_100.w2v.wv.vectors.npy'\n",
        "vocab_size = 51921\n",
        "embed_size = 100\n",
        "num_filters = 50\n",
        "kernel_sizes = [3, 5, 9, 15, 19, 25]\n",
        "dropout = 0.2\n",
        "\n",
        "model = load_model(model_path, embed_file, vocab_size, embed_size, num_filters, kernel_sizes, dropout)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "MQ-ATS6Dr5LN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHs0KeY2CrAl"
      },
      "source": [
        "### **Training**\n",
        "\n",
        "#### **Training Objectives**\n",
        "  * Loss Functions:\n",
        "    * Binary Cross-Entropy Loss: Used for binary classification tasks such as ICD code prediction from clinical texts.\n",
        "    * Asymmetric Loss: Customized to handle imbalanced datasets, focusing more on the minority classes which are crucial in medical code predictions.\n",
        "  * Optimizer:\n",
        "    * Adam Optimizer: Widely used for its efficiency in handling sparse gradients and adaptive learning rate capabilities.\n",
        "\n",
        "The models were first trained locally on a computer with 16GB of RAM and 128MB of GPU memory. Additionally the data was loaded into Google Drive and model training was done on the cloud using this Google Colab notebook “Team26_Colab_Notebook_1.ipynb”.\n",
        "\n",
        "The training program is run through script ‘main.py’. Model hyperparameters were maintained in ‘options.py’.\n",
        "* Depth: 5\n",
        "* Epochs: 2, 3, 5, 10, 500\n",
        "* Model: MultiResCNN\n",
        "* Decoder: Hierarchical Hyperbolic\n",
        "* Batch Size: 8, 16\n",
        "* Workers: 1, 8, 16\n",
        "* Drop Out: 0.2\n",
        "* Loss Function: ASL (Asymmetric Loss)\n",
        "\n",
        "#### **Computational Requirements**:\n",
        "As per original paper, Bi-LSTM and MultiResCNN Models were trained on a single NVIDIA Tesla V100 GPU. RAC Reader-based Models required more computational power, utilizing 4 NVIDIA Tesla V100 GPUs for training.\n",
        "\n",
        "I am using a single Tesla T4 GPU for training. The MultiResCNN has been successfully trained.\n",
        "\n",
        "#### **Training Log for MultiResCNN with HiCuA**\n",
        "Below is portion of the training log that was procued during the training of MutiResCNN with HiCuA on my local Windows computer.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "C:\\Users\\ratuls2\\\\- - - -\\cs598>python runs/run_multirescnn_hicua_50.py\n",
        "Namespace(MODEL_DIR='./models', DATA_DIR='./data', MIMIC_3_DIR='./data/mimic3', MIMIC_2_DIR='./data/mimic2', data_path='./data/mimic3/train_full.csv', vocab='./data/mimic3/vocab.csv', Y='full', version='mimic3', MAX_LENGTH=4096, model='MultiResCNN', decoder='HierarchicalHyperbolic', filter_size='3,5,9,15,19,25', num_filter_maps=50, conv_layer=1, embed_file='./data/mimic3/processed_full_100.embed', hyperbolic_dim=50, test_model=None, use_ext_emb=False, cat_hyperbolic=False, loss='BCE', asl_config='0,0,0', asl_reduction='sum', n_epochs='2,3,5,6,7', depth=5, dropout=0.2, patience=10, batch_size=8, lr=0.0001, weight_decay=0, criterion='prec_at_8', gpu='0', num_workers=0, tune_wordemb=True, random_seed=1, thres=0.5, longformer_dir='', reader_conv_num=2, reader_trans_num=4, trans_ff_dim=1024, num_code_title_tokens=36, code_title_filter_size=9, lstm_hidden_dim=512, attn_dim=512, scheduler=0.9, scheduler_patience=5, command='python main.py', gpu_list=[0])\n",
        "loading lookups...\n",
        "Depth 0: 34\n",
        "Depth 1: 270\n",
        "Depth 2: 1158\n",
        "Depth 3: 5137\n",
        "Depth 4: 8921\n",
        "Training hyperbolic embeddings...\n",
        "loading pretrained embeddings from ./data/mimic3/processed_full_100.embed\n",
        "adding unk embedding\n",
        "MultiResCNN(\n",
        "  (word_rep): WordRep(\n",
        "    (embed): Embedding(51921, 100, padding_idx=0)\n",
        "    (embed_drop): Dropout(p=0.2, inplace=False)\n",
        "  )\n",
        "  (conv): ModuleList(\n",
        "    (channel-3): ModuleList(\n",
        "      (baseconv): Conv1d(100, 100, kernel_size=(3,), stride=(1,), padding=(1,))\n",
        "      (resconv-0): ResidualBlock(\n",
        "        (left): Sequential(\n",
        "          (0): Conv1d(100, 50, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
        "          (1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "          (2): Tanh()\n",
        "          (3): Conv1d(50, 50, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
        "          (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        )\n",
        "        (shortcut): Sequential(\n",
        "          (0): Conv1d(100, 50, kernel_size=(1,), stride=(1,), bias=False)\n",
        "          (1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        )\n",
        "        (dropout): Dropout(p=0.2, inplace=False)\n",
        "      )\n",
        "    )\n",
        "    (channel-5): ModuleList(\n",
        "      (baseconv): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,))\n",
        "      (resconv-0): ResidualBlock(\n",
        "        (left): Sequential(\n",
        "          (0): Conv1d(100, 50, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
        "          (1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "          (2): Tanh()\n",
        "          (3): Conv1d(50, 50, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
        "          (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        )\n",
        "        (shortcut): Sequential(\n",
        "          (0): Conv1d(100, 50, kernel_size=(1,), stride=(1,), bias=False)\n",
        "          (1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        )\n",
        "        (dropout): Dropout(p=0.2, inplace=False)\n",
        "      )\n",
        "    )\n",
        "    (channel-9): ModuleList(\n",
        "      (baseconv): Conv1d(100, 100, kernel_size=(9,), stride=(1,), padding=(4,))\n",
        "      (resconv-0): ResidualBlock(\n",
        "        (left): Sequential(\n",
        "          (0): Conv1d(100, 50, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
        "          (1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "          (2): Tanh()\n",
        "          (3): Conv1d(50, 50, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
        "          (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        )\n",
        "        (shortcut): Sequential(\n",
        "          (0): Conv1d(100, 50, kernel_size=(1,), stride=(1,), bias=False)\n",
        "          (1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        )\n",
        "        (dropout): Dropout(p=0.2, inplace=False)\n",
        "      )\n",
        "    )\n",
        "    (channel-15): ModuleList(\n",
        "      (baseconv): Conv1d(100, 100, kernel_size=(15,), stride=(1,), padding=(7,))\n",
        "      (resconv-0): ResidualBlock(\n",
        "        (left): Sequential(\n",
        "          (0): Conv1d(100, 50, kernel_size=(15,), stride=(1,), padding=(7,), bias=False)\n",
        "          (1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "          (2): Tanh()\n",
        "          (3): Conv1d(50, 50, kernel_size=(15,), stride=(1,), padding=(7,), bias=False)\n",
        "          (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        )\n",
        "        (shortcut): Sequential(\n",
        "          (0): Conv1d(100, 50, kernel_size=(1,), stride=(1,), bias=False)\n",
        "          (1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        )\n",
        "        (dropout): Dropout(p=0.2, inplace=False)\n",
        "      )\n",
        "    )\n",
        "    (channel-19): ModuleList(\n",
        "      (baseconv): Conv1d(100, 100, kernel_size=(19,), stride=(1,), padding=(9,))\n",
        "      (resconv-0): ResidualBlock(\n",
        "        (left): Sequential(\n",
        "          (0): Conv1d(100, 50, kernel_size=(19,), stride=(1,), padding=(9,), bias=False)\n",
        "          (1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "          (2): Tanh()\n",
        "          (3): Conv1d(50, 50, kernel_size=(19,), stride=(1,), padding=(9,), bias=False)\n",
        "          (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        )\n",
        "        (shortcut): Sequential(\n",
        "          (0): Conv1d(100, 50, kernel_size=(1,), stride=(1,), bias=False)\n",
        "          (1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        )\n",
        "        (dropout): Dropout(p=0.2, inplace=False)\n",
        "      )\n",
        "    )\n",
        "    (channel-25): ModuleList(\n",
        "      (baseconv): Conv1d(100, 100, kernel_size=(25,), stride=(1,), padding=(12,))\n",
        "      (resconv-0): ResidualBlock(\n",
        "        (left): Sequential(\n",
        "          (0): Conv1d(100, 50, kernel_size=(25,), stride=(1,), padding=(12,), bias=False)\n",
        "          (1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "          (2): Tanh()\n",
        "          (3): Conv1d(50, 50, kernel_size=(25,), stride=(1,), padding=(12,), bias=False)\n",
        "          (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        )\n",
        "        (shortcut): Sequential(\n",
        "          (0): Conv1d(100, 50, kernel_size=(1,), stride=(1,), bias=False)\n",
        "          (1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        )\n",
        "        (dropout): Dropout(p=0.2, inplace=False)\n",
        "      )\n",
        "    )\n",
        "  )\n",
        "  (decoder): Decoder(\n",
        "    (decoder_dict): ModuleDict(\n",
        "      (0_0): Linear(in_features=300, out_features=34, bias=True)\n",
        "      (0_1): Linear(in_features=300, out_features=34, bias=True)\n",
        "      (1_0): Linear(in_features=300, out_features=270, bias=True)\n",
        "      (1_1): Linear(in_features=300, out_features=270, bias=True)\n",
        "      (2_0): Linear(in_features=300, out_features=1158, bias=True)\n",
        "      (2_1): Linear(in_features=300, out_features=1158, bias=True)\n",
        "      (3_0): Linear(in_features=300, out_features=5137, bias=True)\n",
        "      (3_1): Linear(in_features=300, out_features=5137, bias=True)\n",
        "      (4_0): Linear(in_features=300, out_features=8921, bias=True)\n",
        "      (4_1): Linear(in_features=300, out_features=8921, bias=True)\n",
        "    )\n",
        "    (hyperbolic_fc_dict): ModuleDict(\n",
        "      (0): Linear(in_features=50, out_features=300, bias=True)\n",
        "      (1): Linear(in_features=50, out_features=300, bias=True)\n",
        "      (2): Linear(in_features=50, out_features=300, bias=True)\n",
        "      (3): Linear(in_features=50, out_features=300, bias=True)\n",
        "      (4): Linear(in_features=50, out_features=300, bias=True)\n",
        "    )\n",
        "    (loss_function): BCEWithLogitsLoss()\n",
        "  )\n",
        ")\n",
        "train_instances 47719\n",
        "dev_instances 1631\n",
        "test_instances 3372\n",
        "Total epochs at each level: [2, 3, 5, 6, 7]\n",
        "Training model at depth 0:\n",
        "EPOCH 0\n",
        "epoch finish in 596.55s, loss: 0.2857\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.4733, 0.6131, 0.5658, 0.5885, 0.8732\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.6456, 0.8056, 0.7648, 0.7846, 0.9477\n",
        "rec_at_5: 0.5415\n",
        "prec_at_5: 0.8893\n",
        "rec_at_8: 0.7294\n",
        "prec_at_8: 0.7782\n",
        "rec_at_15: 0.9449\n",
        "prec_at_15: 0.5670\n",
        "\n",
        "evaluation finish in 22.85s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_May_02_10_42_43\n",
        "\n",
        "EPOCH 1\n",
        "epoch finish in 583.58s, loss: 0.2359\n",
        "last epoch: testing on dev and test sets\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.5124, 0.6701, 0.5910, 0.6280, 0.9013\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.6671, 0.8445, 0.7605, 0.8003, 0.9568\n",
        "rec_at_5: 0.5534\n",
        "prec_at_5: 0.9061\n",
        "rec_at_8: 0.7468\n",
        "prec_at_8: 0.7962\n",
        "rec_at_15: 0.9547\n",
        "prec_at_15: 0.5734\n",
        "\n",
        "evaluation finish in 20.58s\n",
        "file for evaluation: ./data/mimic3/test_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.5097, 0.6748, 0.5841, 0.6262, 0.8887\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.6760, 0.8493, 0.7681, 0.8067, 0.9560\n",
        "rec_at_5: 0.5487\n",
        "prec_at_5: 0.9071\n",
        "rec_at_8: 0.7395\n",
        "prec_at_8: 0.7998\n",
        "rec_at_15: 0.9525\n",
        "prec_at_15: 0.5789\n",
        "\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_May_02_10_42_43\n",
        "\n",
        "Training model at depth 1:\n",
        "EPOCH 0\n",
        "epoch finish in 602.27s, loss: 0.0849\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.2137, 0.3604, 0.2532, 0.2975, 0.8768\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.5062, 0.8023, 0.5783, 0.6722, 0.9694\n",
        "rec_at_5: 0.3800\n",
        "prec_at_5: 0.8806\n",
        "rec_at_8: 0.5319\n",
        "prec_at_8: 0.7971\n",
        "rec_at_15: 0.7243\n",
        "prec_at_15: 0.6121\n",
        "\n",
        "evaluation finish in 20.69s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_May_02_10_42_43\n",
        "\n",
        "EPOCH 1\n",
        "epoch finish in 602.62s, loss: 0.0708\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.2532, 0.4027, 0.2975, 0.3422, 0.9070\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.5433, 0.8124, 0.6212, 0.7041, 0.9751\n",
        "rec_at_5: 0.3885\n",
        "prec_at_5: 0.8961\n",
        "rec_at_8: 0.5488\n",
        "prec_at_8: 0.8191\n",
        "rec_at_15: 0.7512\n",
        "prec_at_15: 0.6336\n",
        "\n",
        "evaluation finish in 21.34s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_May_02_10_42_43\n",
        "\n",
        "EPOCH 2\n",
        "epoch finish in 604.43s, loss: 0.0660\n",
        "last epoch: testing on dev and test sets\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.2826, 0.4337, 0.3346, 0.3778, 0.9193\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.5602, 0.8099, 0.6450, 0.7181, 0.9775\n",
        "rec_at_5: 0.3944\n",
        "prec_at_5: 0.9051\n",
        "rec_at_8: 0.5572\n",
        "prec_at_8: 0.8296\n",
        "rec_at_15: 0.7627\n",
        "prec_at_15: 0.6423\n",
        "\n",
        "evaluation finish in 21.49s\n",
        "file for evaluation: ./data/mimic3/test_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.2854, 0.4575, 0.3374, 0.3883, 0.9202\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.5594, 0.8069, 0.6459, 0.7175, 0.9768\n",
        "rec_at_5: 0.3845\n",
        "prec_at_5: 0.9022\n",
        "rec_at_8: 0.5458\n",
        "prec_at_8: 0.8309\n",
        "rec_at_15: 0.7542\n",
        "prec_at_15: 0.6505\n",
        "\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_May_02_10_42_43\n",
        "\n",
        "Training model at depth 2:\n",
        "EPOCH 0\n",
        "epoch finish in 663.95s, loss: 0.0263\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.0978, 0.1784, 0.1148, 0.1397, 0.9067\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.4456, 0.7797, 0.5098, 0.6165, 0.9815\n",
        "rec_at_5: 0.3273\n",
        "prec_at_5: 0.8558\n",
        "rec_at_8: 0.4646\n",
        "prec_at_8: 0.7831\n",
        "rec_at_15: 0.6423\n",
        "prec_at_15: 0.6087\n",
        "\n",
        "evaluation finish in 23.17s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_May_02_10_42_43\n",
        "\n",
        "EPOCH 1\n",
        "epoch finish in 664.65s, loss: 0.0229\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.1248, 0.2094, 0.1496, 0.1745, 0.9199\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.4817, 0.7682, 0.5637, 0.6502, 0.9842\n",
        "rec_at_5: 0.3367\n",
        "prec_at_5: 0.8739\n",
        "rec_at_8: 0.4775\n",
        "prec_at_8: 0.8015\n",
        "rec_at_15: 0.6605\n",
        "prec_at_15: 0.6262\n",
        "\n",
        "evaluation finish in 22.70s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_May_02_10_42_43\n",
        "\n",
        "EPOCH 2\n",
        "epoch finish in 670.18s, loss: 0.0217\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.1399, 0.2289, 0.1696, 0.1948, 0.9266\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.4923, 0.7702, 0.5771, 0.6598, 0.9855\n",
        "rec_at_5: 0.3396\n",
        "prec_at_5: 0.8813\n",
        "rec_at_8: 0.4823\n",
        "prec_at_8: 0.8090\n",
        "rec_at_15: 0.6715\n",
        "prec_at_15: 0.6359\n",
        "\n",
        "evaluation finish in 22.96s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_May_02_10_42_43\n",
        "\n",
        "EPOCH 3\n",
        "epoch finish in 665.78s, loss: 0.0209\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.1522, 0.2497, 0.1816, 0.2103, 0.9316\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.4976, 0.7822, 0.5777, 0.6645, 0.9864\n",
        "rec_at_5: 0.3423\n",
        "prec_at_5: 0.8853\n",
        "rec_at_8: 0.4870\n",
        "prec_at_8: 0.8134\n",
        "rec_at_15: 0.6778\n",
        "prec_at_15: 0.6408\n",
        "\n",
        "evaluation finish in 21.52s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_May_02_10_42_43\n",
        "\n",
        "EPOCH 4\n",
        "epoch finish in 662.12s, loss: 0.0203\n",
        "last epoch: testing on dev and test sets\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.1603, 0.2607, 0.1933, 0.2220, 0.9344\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.5024, 0.7742, 0.5887, 0.6688, 0.9867\n",
        "rec_at_5: 0.3427\n",
        "prec_at_5: 0.8860\n",
        "rec_at_8: 0.4880\n",
        "prec_at_8: 0.8143\n",
        "rec_at_15: 0.6807\n",
        "prec_at_15: 0.6430\n",
        "\n",
        "evaluation finish in 23.00s\n",
        "file for evaluation: ./data/mimic3/test_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.1712, 0.2853, 0.2053, 0.2388, 0.9336\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.5034, 0.7765, 0.5887, 0.6697, 0.9866\n",
        "rec_at_5: 0.3342\n",
        "prec_at_5: 0.8850\n",
        "rec_at_8: 0.4759\n",
        "prec_at_8: 0.8174\n",
        "rec_at_15: 0.6725\n",
        "prec_at_15: 0.6536\n",
        "\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_May_02_10_42_43\n",
        "\n",
        "Training model at depth 3:\n",
        "EPOCH 0\n",
        "epoch finish in 931.92s, loss: 0.0080\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.0439, 0.0782, 0.0534, 0.0635, 0.9266\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.3853, 0.7347, 0.4476, 0.5563, 0.9882\n",
        "rec_at_5: 0.2927\n",
        "prec_at_5: 0.8200\n",
        "rec_at_8: 0.4108\n",
        "prec_at_8: 0.7405\n",
        "rec_at_15: 0.5749\n",
        "prec_at_15: 0.5815\n",
        "\n",
        "evaluation finish in 27.13s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_May_02_10_42_43\n",
        "\n",
        "EPOCH 1\n",
        "epoch finish in 931.13s, loss: 0.0069\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.0547, 0.0907, 0.0658, 0.0763, 0.9341\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.4101, 0.7437, 0.4775, 0.5816, 0.9893\n",
        "rec_at_5: 0.2999\n",
        "prec_at_5: 0.8372\n",
        "rec_at_8: 0.4228\n",
        "prec_at_8: 0.7615\n",
        "rec_at_15: 0.5928\n",
        "prec_at_15: 0.6009\n",
        "\n",
        "evaluation finish in 26.99s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_May_02_10_42_43\n",
        "\n",
        "EPOCH 2\n",
        "epoch finish in 929.08s, loss: 0.0066\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.0620, 0.1009, 0.0757, 0.0865, 0.9380\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.4249, 0.7296, 0.5044, 0.5964, 0.9899\n",
        "rec_at_5: 0.3034\n",
        "prec_at_5: 0.8465\n",
        "rec_at_8: 0.4280\n",
        "prec_at_8: 0.7702\n",
        "rec_at_15: 0.5999\n",
        "prec_at_15: 0.6079\n",
        "\n",
        "evaluation finish in 27.46s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_May_02_10_42_43\n",
        "\n",
        "EPOCH 3\n",
        "epoch finish in 929.07s, loss: 0.0064\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.0661, 0.1056, 0.0803, 0.0912, 0.9406\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.4280, 0.7367, 0.5052, 0.5994, 0.9903\n",
        "rec_at_5: 0.3038\n",
        "prec_at_5: 0.8481\n",
        "rec_at_8: 0.4302\n",
        "prec_at_8: 0.7725\n",
        "rec_at_15: 0.6045\n",
        "prec_at_15: 0.6122\n",
        "\n",
        "evaluation finish in 26.25s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_May_02_10_42_43\n",
        "\n",
        "EPOCH 4\n",
        "epoch finish in 927.61s, loss: 0.0062\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.0698, 0.1112, 0.0845, 0.0960, 0.9417\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.4314, 0.7393, 0.5088, 0.6028, 0.9905\n",
        "rec_at_5: 0.3053\n",
        "prec_at_5: 0.8502\n",
        "rec_at_8: 0.4333\n",
        "prec_at_8: 0.7774\n",
        "rec_at_15: 0.6073\n",
        "prec_at_15: 0.6149\n",
        "\n",
        "evaluation finish in 26.22s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_May_02_10_42_43\n",
        "\n",
        "EPOCH 5\n",
        "epoch finish in 927.58s, loss: 0.0061\n",
        "last epoch: testing on dev and test sets\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.0719, 0.1147, 0.0854, 0.0979, 0.9423\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.4323, 0.7493, 0.5054, 0.6037, 0.9906\n",
        "rec_at_5: 0.3073\n",
        "prec_at_5: 0.8533\n",
        "rec_at_8: 0.4336\n",
        "prec_at_8: 0.7784\n",
        "rec_at_15: 0.6089\n",
        "prec_at_15: 0.6173\n",
        "\n",
        "evaluation finish in 27.07s\n",
        "file for evaluation: ./data/mimic3/test_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.0772, 0.1334, 0.0933, 0.1098, 0.9434\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.4289, 0.7456, 0.5024, 0.6003, 0.9905\n",
        "rec_at_5: 0.2973\n",
        "prec_at_5: 0.8492\n",
        "rec_at_8: 0.4195\n",
        "prec_at_8: 0.7773\n",
        "rec_at_15: 0.5961\n",
        "prec_at_15: 0.6237\n",
        "\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_May_02_10_42_43\n",
        "\n",
        "Training model at depth 4:\n",
        "EPOCH 0\n",
        "epoch finish in 1243.63s, loss: 0.0046\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.0392, 0.0643, 0.0481, 0.0550, 0.9424\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.3676, 0.7115, 0.4319, 0.5375, 0.9899\n",
        "rec_at_5: 0.2834\n",
        "prec_at_5: 0.8044\n",
        "rec_at_8: 0.3958\n",
        "prec_at_8: 0.7256\n",
        "rec_at_15: 0.5537\n",
        "prec_at_15: 0.5691\n",
        "\n",
        "evaluation finish in 36.42s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_May_02_10_42_43\n",
        "\n",
        "EPOCH 1\n",
        "epoch finish in 1238.86s, loss: 0.0043\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.0457, 0.0726, 0.0559, 0.0632, 0.9449\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.3805, 0.7085, 0.4512, 0.5513, 0.9904\n",
        "rec_at_5: 0.2870\n",
        "prec_at_5: 0.8132\n",
        "rec_at_8: 0.4013\n",
        "prec_at_8: 0.7344\n",
        "rec_at_15: 0.5625\n",
        "prec_at_15: 0.5791\n",
        "\n",
        "evaluation finish in 37.77s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_May_02_10_42_43\n",
        "\n",
        "EPOCH 2\n",
        "epoch finish in 1240.62s, loss: 0.0041\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.0471, 0.0755, 0.0571, 0.0650, 0.9460\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.3804, 0.7193, 0.4467, 0.5511, 0.9906\n",
        "rec_at_5: 0.2871\n",
        "prec_at_5: 0.8155\n",
        "rec_at_8: 0.4047\n",
        "prec_at_8: 0.7406\n",
        "rec_at_15: 0.5663\n",
        "prec_at_15: 0.5833\n",
        "\n",
        "evaluation finish in 37.89s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_May_02_10_42_43\n",
        "\n",
        "EPOCH 3\n",
        "epoch finish in 1243.17s, loss: 0.0040\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.0496, 0.0779, 0.0599, 0.0677, 0.9471\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.3866, 0.7153, 0.4570, 0.5577, 0.9907\n",
        "rec_at_5: 0.2875\n",
        "prec_at_5: 0.8169\n",
        "rec_at_8: 0.4045\n",
        "prec_at_8: 0.7413\n",
        "rec_at_15: 0.5672\n",
        "prec_at_15: 0.5852\n",
        "\n",
        "evaluation finish in 36.17s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_May_02_10_42_43\n",
        "\n",
        "EPOCH 4\n",
        "epoch finish in 1242.55s, loss: 0.0039\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.0517, 0.0808, 0.0627, 0.0706, 0.9471\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.3912, 0.7052, 0.4677, 0.5624, 0.9908\n",
        "rec_at_5: 0.2890\n",
        "prec_at_5: 0.8188\n",
        "rec_at_8: 0.4048\n",
        "prec_at_8: 0.7421\n",
        "rec_at_15: 0.5685\n",
        "prec_at_15: 0.5860\n",
        "\n",
        "evaluation finish in 38.04s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_May_02_10_42_43\n",
        "\n",
        "EPOCH 5\n",
        "epoch finish in 1239.93s, loss: 0.0039\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.0533, 0.0832, 0.0644, 0.0726, 0.9468\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.3917, 0.7112, 0.4658, 0.5629, 0.9906\n",
        "rec_at_5: 0.2887\n",
        "prec_at_5: 0.8188\n",
        "rec_at_8: 0.4061\n",
        "prec_at_8: 0.7440\n",
        "rec_at_15: 0.5700\n",
        "prec_at_15: 0.5870\n",
        "\n",
        "evaluation finish in 38.00s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_May_02_10_42_43\n",
        "\n",
        "EPOCH 6\n",
        "epoch finish in 1240.48s, loss: 0.0038\n",
        "last epoch: testing on dev and test sets\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.0545, 0.0848, 0.0652, 0.0737, 0.9464\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.3949, 0.7101, 0.4708, 0.5662, 0.9907\n",
        "rec_at_5: 0.2894\n",
        "prec_at_5: 0.8213\n",
        "rec_at_8: 0.4068\n",
        "prec_at_8: 0.7458\n",
        "rec_at_15: 0.5710\n",
        "prec_at_15: 0.5885\n",
        "\n",
        "evaluation finish in 35.74s\n",
        "file for evaluation: ./data/mimic3/test_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.0626, 0.1049, 0.0768, 0.0887, 0.9470\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.3886, 0.7053, 0.4639, 0.5597, 0.9904\n",
        "rec_at_5: 0.2791\n",
        "prec_at_5: 0.8187\n",
        "rec_at_8: 0.3934\n",
        "prec_at_8: 0.7454\n",
        "rec_at_15: 0.5546\n",
        "prec_at_15: 0.5922\n",
        "\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_May_02_10_42_43\n",
        "```"
      ],
      "metadata": {
        "id": "NJu5d5HctrZg"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWmpSGJSCwEP"
      },
      "source": [
        "### **Evaluation**\n",
        "\n",
        "#### **Metrics Used in Evaluation**:\n",
        "  * AUC (Area Under the Curve): Utilized in both micro-averaged and macro-averaged forms, this metric measures the overall prediction performance across all labels.\n",
        "  * F1 Score: Reported in both micro-averaged and macro-averaged forms, it indicates the balance between precision and recall.\n",
        "  * Precision@K (P@K): This metric assesses the proportion of correctly predicted labels in the top-K predictions, essential for practical applications where only the top few predictions may be considered.\n",
        "\n",
        "The new model performance was compared with the original hierarchical model build on CAML, DR-CAML, HyperCore etc.\n",
        "\n",
        "#### **Performance Results**:\n",
        "  * The HiCu method was tested on several model architectures, showing improvements in AUC and F1 scores over baseline models without curriculum learning.\n",
        "  * Notable enhancements were particularly evident for rare labels, addressing the challenge of imbalanced datasets prevalent in medical coding.\n",
        "  * An asymmetric loss function was employed to handle label imbalance more effectively, leading to superior performance on rare and infrequent labels.\n",
        "  * Extensive testing was conducted on the MIMIC-III dataset using ICD-9 codes, establishing the method's effectiveness on a standard dataset for medical coding research.\n",
        "\n",
        "Below code was used to implement calculation of AUC, F1, and Precision@K metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "def print_metrics(metrics):\n",
        "    print()\n",
        "    if \"auc_macro\" in metrics.keys():\n",
        "        print(\"[MACRO] accuracy, precision, recall, f-measure, AUC\")\n",
        "        print(\"%.4f, %.4f, %.4f, %.4f, %.4f\" % (metrics[\"acc_macro\"], metrics[\"prec_macro\"], metrics[\"rec_macro\"], metrics[\"f1_macro\"], metrics[\"auc_macro\"]))\n",
        "    else:\n",
        "        print(\"[MACRO] accuracy, precision, recall, f-measure\")\n",
        "        print(\"%.4f, %.4f, %.4f, %.4f\" % (metrics[\"acc_macro\"], metrics[\"prec_macro\"], metrics[\"rec_macro\"], metrics[\"f1_macro\"]))\n",
        "\n",
        "    if \"auc_micro\" in metrics.keys():\n",
        "        print(\"[MICRO] accuracy, precision, recall, f-measure, AUC\")\n",
        "        print(\"%.4f, %.4f, %.4f, %.4f, %.4f\" % (metrics[\"acc_micro\"], metrics[\"prec_micro\"], metrics[\"rec_micro\"], metrics[\"f1_micro\"], metrics[\"auc_micro\"]))\n",
        "    else:\n",
        "        print(\"[MICRO] accuracy, precision, recall, f-measure\")\n",
        "        print(\"%.4f, %.4f, %.4f, %.4f\" % (metrics[\"acc_micro\"], metrics[\"prec_micro\"], metrics[\"rec_micro\"], metrics[\"f1_micro\"]))\n",
        "    for metric, val in metrics.items():\n",
        "        if metric.find(\"rec_at\") != -1:\n",
        "            print(\"%s: %.4f\" % (metric, val))\n",
        "    print()\n",
        "\n",
        "def union_size(yhat, y, axis):\n",
        "    #axis=0 for label-level union (macro). axis=1 for instance-level\n",
        "    return np.logical_or(yhat, y).sum(axis=axis).astype(float)\n",
        "\n",
        "def intersect_size(yhat, y, axis):\n",
        "    #axis=0 for label-level union (macro). axis=1 for instance-level\n",
        "    return np.logical_and(yhat, y).sum(axis=axis).astype(float)\n",
        "\n",
        "def macro_accuracy(yhat, y):\n",
        "    num = intersect_size(yhat, y, 0) / (union_size(yhat, y, 0) + 1e-10)\n",
        "    return np.mean(num)\n",
        "\n",
        "def macro_precision(yhat, y):\n",
        "    num = intersect_size(yhat, y, 0) / (yhat.sum(axis=0) + 1e-10)\n",
        "    return np.mean(num)\n",
        "\n",
        "def macro_recall(yhat, y):\n",
        "    num = intersect_size(yhat, y, 0) / (y.sum(axis=0) + 1e-10)\n",
        "    return np.mean(num)\n",
        "\n",
        "def macro_f1(yhat, y):\n",
        "    prec = macro_precision(yhat, y)\n",
        "    rec = macro_recall(yhat, y)\n",
        "    if prec + rec == 0:\n",
        "        f1 = 0.\n",
        "    else:\n",
        "        f1 = 2*(prec*rec)/(prec+rec)\n",
        "    return f1\n",
        "\n",
        "\n",
        "def all_macro(yhat, y):\n",
        "    return macro_accuracy(yhat, y), macro_precision(yhat, y), macro_recall(yhat, y), macro_f1(yhat, y)\n",
        "\n",
        "def micro_accuracy(yhatmic, ymic):\n",
        "    return intersect_size(yhatmic, ymic, 0) / (union_size(yhatmic, ymic, 0) + 1e-10)\n",
        "\n",
        "def micro_precision(yhatmic, ymic):\n",
        "    return intersect_size(yhatmic, ymic, 0) / (yhatmic.sum(axis=0) + 1e-10)\n",
        "\n",
        "def micro_recall(yhatmic, ymic):\n",
        "    return intersect_size(yhatmic, ymic, 0) / (ymic.sum(axis=0) + 1e-10)\n",
        "\n",
        "def micro_f1(yhatmic, ymic):\n",
        "    prec = micro_precision(yhatmic, ymic)\n",
        "    rec = micro_recall(yhatmic, ymic)\n",
        "    if prec + rec == 0:\n",
        "        f1 = 0.\n",
        "    else:\n",
        "        f1 = 2 * (prec * rec) / (prec + rec)\n",
        "    return f1\n",
        "\n",
        "def all_micro(yhatmic, ymic):\n",
        "    return micro_accuracy(yhatmic, ymic), micro_precision(yhatmic, ymic), micro_recall(yhatmic, ymic), micro_f1(yhatmic, ymic)\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "def auc_metrics(yhat_raw, y, ymic):\n",
        "    if yhat_raw.shape[0] <= 1:\n",
        "        return\n",
        "    fpr = {}\n",
        "    tpr = {}\n",
        "    roc_auc = {}\n",
        "    #get AUC for each label individually\n",
        "    relevant_labels = []\n",
        "    auc_labels = {}\n",
        "    for i in range(y.shape[1]):\n",
        "        #only if there are true positives for this label\n",
        "        if y[:,i].sum() > 0:\n",
        "            fpr[i], tpr[i], _ = roc_curve(y[:,i], yhat_raw[:,i])\n",
        "            if len(fpr[i]) > 1 and len(tpr[i]) > 1:\n",
        "                auc_score = auc(fpr[i], tpr[i])\n",
        "                if not np.isnan(auc_score):\n",
        "                    auc_labels[\"auc_%d\" % i] = auc_score\n",
        "                    relevant_labels.append(i)\n",
        "\n",
        "    #macro-AUC: just average the auc scores\n",
        "    aucs = []\n",
        "    for i in relevant_labels:\n",
        "        aucs.append(auc_labels['auc_%d' % i])\n",
        "    roc_auc['auc_macro'] = np.mean(aucs)\n",
        "\n",
        "    #micro-AUC: just look at each individual prediction\n",
        "    yhatmic = yhat_raw.ravel()\n",
        "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(ymic, yhatmic)\n",
        "    roc_auc[\"auc_micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "    return roc_auc\n",
        "\n",
        "def recall_at_k(yhat_raw, y, k):\n",
        "    #num true labels in top k predictions / num true labels\n",
        "    sortd = np.argsort(yhat_raw)[:,::-1]\n",
        "    topk = sortd[:,:k]\n",
        "\n",
        "    #get recall at k for each example\n",
        "    vals = []\n",
        "    for i, tk in enumerate(topk):\n",
        "        num_true_in_top_k = y[i,tk].sum()\n",
        "        denom = y[i,:].sum()\n",
        "        vals.append(num_true_in_top_k / float(denom))\n",
        "\n",
        "    vals = np.array(vals)\n",
        "    vals[np.isnan(vals)] = 0.\n",
        "\n",
        "    return np.mean(vals)\n",
        "\n",
        "def precision_at_k(yhat_raw, y, k):\n",
        "    #num true labels in top k predictions / k\n",
        "    sortd = np.argsort(yhat_raw)[:,::-1]\n",
        "    topk = sortd[:,:k]\n",
        "\n",
        "    #get precision at k for each example\n",
        "    vals = []\n",
        "    for i, tk in enumerate(topk):\n",
        "        if len(tk) > 0:\n",
        "            num_true_in_top_k = y[i,tk].sum()\n",
        "            denom = len(tk)\n",
        "            vals.append(num_true_in_top_k / float(denom))\n",
        "\n",
        "    return np.mean(vals)\n",
        "\n",
        "def all_metrics(yhat, y, k=8, yhat_raw=None, calc_auc=True):\n",
        "    \"\"\"\n",
        "        Inputs:\n",
        "            yhat: binary predictions matrix\n",
        "            y: binary ground truth matrix\n",
        "            k: for @k metrics\n",
        "            yhat_raw: prediction scores matrix (floats)\n",
        "        Outputs:\n",
        "            dict holding relevant metrics\n",
        "    \"\"\"\n",
        "    names = [\"acc\", \"prec\", \"rec\", \"f1\"]\n",
        "\n",
        "    #macro\n",
        "    macro = all_macro(yhat, y)\n",
        "\n",
        "    #micro\n",
        "    ymic = y.ravel()\n",
        "    yhatmic = yhat.ravel()\n",
        "    micro = all_micro(yhatmic, ymic)\n",
        "\n",
        "    metrics = {names[i] + \"_macro\": macro[i] for i in range(len(macro))}\n",
        "    metrics.update({names[i] + \"_micro\": micro[i] for i in range(len(micro))})\n",
        "\n",
        "    #AUC and @k\n",
        "    if yhat_raw is not None and calc_auc:\n",
        "        #allow k to be passed as int or list\n",
        "        if type(k) != list:\n",
        "            k = [k]\n",
        "        for k_i in k:\n",
        "            rec_at_k = recall_at_k(yhat_raw, y, k_i)\n",
        "            metrics['rec_at_%d' % k_i] = rec_at_k\n",
        "            prec_at_k = precision_at_k(yhat_raw, y, k_i)\n",
        "            metrics['prec_at_%d' % k_i] = prec_at_k\n",
        "            metrics['f1_at_%d' % k_i] = 2*(prec_at_k*rec_at_k)/(prec_at_k+rec_at_k)\n",
        "\n",
        "        roc_auc = auc_metrics(yhat_raw, y, ymic)\n",
        "        metrics.update(roc_auc)\n",
        "\n",
        "    return metrics\n",
        "```"
      ],
      "metadata": {
        "id": "VGRjMU4WxS7r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below Google Colab code snippet was used to:\n",
        "  * Mount Google Drive at Colab.\n",
        "  * Copy complete project folder from Google Drive to Colab for faster processing.\n",
        "  * Model training by executing the respective Python program. Each program has its parameters set inside.\n",
        "\n",
        "Once the training program execution is complete, the output is saved at **\"/models\"** folder. It contains **config.csv** (contains the model parameters), **metrics.json** (contains the performance metrics) and **model_best_prec_at_8.pth** (built model)."
      ],
      "metadata": {
        "id": "azQ8miCnxyLr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJ-rYa59DFba"
      },
      "outputs": [],
      "source": [
        "# Code to mount Google drive:\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# To Copy Google Drive to Google Colab local drive:\n",
        "!cp -r '/content/drive/MyDrive/HiCu-ICD-Team26-Spring24' '/content/'\n",
        "\n",
        "# Model training:\n",
        "# Different training scripts were run with the desired model configuration\n",
        "!python /content/HiCu-ICD-Team26-Spring24/runs/run_multirescnn_50.py\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kaj0fZGgDcDx"
      },
      "source": [
        "# **Results**\n",
        "***\n",
        "As per the research paper, the HiCu model and its implementation on different encoders showed model performance improvements. AUC, F1 and Precion@K attributes were compared between performance outcomes from various runs on different models.\n",
        "It was observed, when the model was run deep (higher depth) into the hierarchy, and the epoch count increased, it resulted in lesser loss function.\n",
        "\n",
        "A sample output of the model performance:\n",
        "```\n",
        "epoch finish in 189.40s, loss: 0.1643\n",
        "file for evaluation: ./data/mimic3/dev_50.csv\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.4113, 0.6294, 0.5163, 0.5673, 0.8816\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.4590, 0.7112, 0.5641, 0.6292, 0.9161\n",
        "rec_at_5: 0.5904\n",
        "prec_at_5: 0.6037\n",
        "rec_at_8: 0.7229\n",
        "prec_at_8: 0.4864\n",
        "rec_at_15: 0.8768\n",
        "prec_at_15: 0.3299\n",
        "```\n",
        "\n",
        "### **Analyses**\n",
        "\n",
        "Due to large quantity of data and low availability of higher-power GPUs, model was run with a single GPU, and only for few epochs.\n",
        "\n",
        "I ran the MultiResCNN model with a HierarchicalHyperbolic decoder, that is designed to address the complexities of medical text classification. My objective was to evaluate the model's effectiveness across various hierarchical depths, with a specific focus on precision at depth 8 (prec_at_8) as the primary criterion. Below is the configuration, and a summary of results across multiple depths. My results are compared with the existing benchmarks from the original paper.\n",
        "\n",
        "### **Model Configuration (pertinent to both Claims 1 & 2)**\n",
        "\n",
        "* Model: MultiResCNN with HierarchicalHyperbolic decoder\n",
        "* Batch size: 8\n",
        "* Learning rate: 5e-05\n",
        "* Dropout: 0.2\n",
        "* Depth: 5\n",
        "* Random Seed: 1\n",
        "* Number of Workers: 0\n",
        "* Filters sizes: filter_size 3,5,9,15,19,25\n",
        "* Criterion: Precision at depth 8 (prec_at_8)\n",
        "* Loss: BCE\n",
        "\n",
        "\n",
        "### **Models variations available in the Github repo:**\n",
        "* **MultiResCNN** model varieties executed:\n",
        "  *\t**Without HiCu**: MultiResCNN_50, MultiResCNN_full\n",
        "  * **With HiCu**: MultiResCNN_HiCuA_50, MultiResCNN_HiCuA_full,MultiResCNN_HiCuA_asl_50, MultiResCNN_HiCuA_asl_full\n",
        "\n",
        "*\t**RAC** model varieties appear to be more resource demanding. I was not been able to run due to resource constraints on Google Colab Pro.\n",
        "\n",
        "*\t**LAAT** model varieties were not run due to time constraints.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Result Summary**\n",
        "The MultiResCNN model with HierarchicalHyperbolic decoder, was trained with depth 5.\n",
        "This model used:\n",
        "  * **training data**: './data/mimic3/train_full.csv'\n",
        "  * **vocabulary data**: './data/mimic3/vocab.csv'\n",
        "  * **embed file**: './data/mimic3/processed_full_100.embed'\n",
        "\n",
        "Below are detailed results for **Claim 1** (attempt to run authors' original algorithm).\n",
        "\n",
        "#### **Metrics at Depth 0**:\n",
        "  * AUC (Macro): 0.8732, 0.9013, 0.8887 (Best: 0.9013)\n",
        "  * AUC (Micro): 0.9477, 0.9568, 0.9560 (Best: 0.9568)\n",
        "  * Loss: 0.2857, 0.2359 (Best: 0.2359)\n",
        "  * F1 (Macro): 0.5885, 0.6280, 0.6262 (Best: 0.6280)\n",
        "  * F1 (Micro): 0.7846, 0.8003, 0.8067 (Best: 0.8067)\n",
        "  * Precision@8: 0.7782, 0.7962, 0.7998 (Best: 0.7998)\n",
        "\n",
        "#### **Metrics at Depth 1**:\n",
        "  * AUC (Macro): 0.8768, 0.9070, 0.9193, 0.9202 (Best: 0.9202)\n",
        "  * AUC (Micro): 0.9694, 0.9751, 0.9775, 0.9768 (Best: 0.9775)\n",
        "  * Loss: 0.0849, 0.0708, 0.0660 (Best: 0.0660)\n",
        "  * F1 (Macro): 0.2975, 0.3422, 0.3778, 0.3883 (Best: 0.3883)\n",
        "  * F1 (Micro): 0.6722, 0.7041, 0.7181, 0.7175 (Best: 0.7181)\n",
        "  * Precision@8: 0.7971, 0.8191, 0.8296, 0.8309 (Best: 0.8309)\n",
        "\n",
        "#### **Metrics at Depth 2**:\n",
        "  * AUC (Macro): 0.9067, 0.9199, 0.9266, 0.9316, 0.9344, 0.9336 (Best: 0.9344)\n",
        "  * AUC (Micro): 0.9815, 0.9842, 0.9855, 0.9864, 0.9867, 0.9866 (Best: 0.9867)\n",
        "  * Loss: 0.0263, 0.0229, 0.0217, 0.0209, 0.0203 (Best: 0.0203)\n",
        "  * F1 (Macro): 0.1397, 0.1745, 0.1948, 0.2103, 0.2220, 0.2388 (Best: 0.2388)\n",
        "  * F1 (Micro): 0.6165, 0.6502, 0.6598, 0.6645, 0.6688, 0.6697 (Best: 0.6697)\n",
        "  * Precision@8: 0.7831, 0.8015, 0.8090, 0.8134, 0.8143, 0.8174 (Best: 0.8174)\n",
        "\n",
        "#### **Metrics at Depth 3**:\n",
        "  * AUC (Macro): 0.9266, 0.9341, 0.9380, 0.9406, 0.9417, 0.9423, 0.9434 (Best: 0.9423)\n",
        "  * AUC (Micro): 0.9882, 0.9893, 0.9899, 0.9903, 0.9905, 0.9906, 0.9905 (Best: 0.9906)\n",
        "  * Loss: 0.0080, 0.0069, 0.0066, 0.0064, 0.0062, 0.0061 (Best: 0.0061)\n",
        "  * F1 (Macro): 0.0635, 0.0763, 0.0865, 0.0912, 0.0960, 0.0979, 0.1098 (Best: 0.1098)\n",
        "  * F1 (Micro): 0.5563, 0.5816, 0.5964, 0.5994, 0.6028, 0.6037, 0.6003 (Best: 0.6037)\n",
        "  * Precision@8: 0.7405, 0.7615, 0.7702, 0.7725, 0.7774, 0.7784, 0.7773 (Best: 0.7784)\n",
        "\n",
        "#### **Metrics at Depth 4**:\n",
        "  * AUC (Macro): 0.9424, 0.9449, 0.9460, 0.9471, 0.9471, 0.9468, 0.9464, 0.9470 (Best: 0.9417)\n",
        "  * AUC (Micro): 0.9899, 0.9904, 0.9906, 0.9907, 0.9908, 0.9906, 0.9907, 0.9904 (Best: 0.9905)\n",
        "  * Loss: 0.0046, 0.0043, 0.0041, 0.0040, 0.0039, 0.0039, 0.0038 (Best: 0.0038)\n",
        "  * F1 (Macro): 0.0550, 0.0632, 0.0650, 0.0677, 0.0706, 0.0726, 0.0737, 0.0887 (Best: 0.0887)\n",
        "  * F1 (Micro): 0.5375, 0.5513, 0.5511, 0.5577, 0.5624. 0.5629, 0.5662, 0.5597 (Best: 0.5662)\n",
        "  * Precision@8: 0.7256, 0.7344, 0.7406, 0.7413, 0.7421, 0.7440, 0.7458, 0.7454 (Best: 0.7458)\n",
        "\n",
        "### **Overall Metrics**:\n",
        "Almost all the metrics improve when the depth increases.\n",
        "  * AUC (Macro): 0.9013, 0.9202, 0.9344, **0.9423**, 0.9417 (Best: 0.9423)\n",
        "  * AUC (Micro): 0.9568, 0.9775, 0.9867, **0.9906**, 0.9905 (Best: 0.9906)\n",
        "  * Loss: 0.2359, 0.0660, 0.0203, 0.0061, **0.0038** (Best: 0.0038)\n",
        "  * F1 (Macro): **0.6280**, 0.3883, 0.2388, 0.1098, 0.0887 (Best: 0.6280)\n",
        "  * F1 (Micro): **0.8067**, 0.7181, 0.6697, 0.6037, 0.5662 (Best: 0.8067)\n",
        "  * Precision@8: 0.7998, **0.8309**, 0.8174, 0.7784, 0.7458 (Best: 0.8309)\n",
        "\n",
        "### **Claim 1: Metrics Comparison with the Original Paper**\n",
        "I compared my experiment metrics with the numbers mentioned in author's original paper.\n",
        "\n",
        "  * AUC (Macro):\n",
        "    * Author's MultiResCNN model Metric: 0.9120\n",
        "    * Author's MultiResCNN with HiCuA Metric: 0.9470\n",
        "    * Claim 1 MultiResCNN with HiCuA Metric: **0.9423**\n",
        "  * AUC (Micro):\n",
        "    * Author's MultiResCNN model Metric: 0.9870\n",
        "    * Author's MultiResCNN with HiCuA Metric: 0.9910\n",
        "    * Claim 1 MultiResCNN with HiCuA Metric: **0.9906**\n",
        "  * Precision@8:\n",
        "    * Author's MultiResCNN model Metric: 0.7430\n",
        "    * Author's MultiResCNN with HiCuA Metric: 0.7480\n",
        "    * Claim 1 MultiResCNN with HiCuA Metric: **0.8309**\n",
        "\n",
        "This indeed proves that the hypothesis \"Claim 1\" stands true: **HiCuA (Hyperbolic Correction Addition) significantly enhances the MultiResCNN model's performance**.\n",
        "\n",
        "For Claim 2, below are the results (attempt to run modified code with Ablation study with flatten heirarchy).\n",
        "\n",
        "### **Claim 2: Metrics Comparison with the Original Paper**\n",
        "I compared my experiment metrics with the numbers mentioned in author's original paper.\n",
        "\n",
        "  * AUC (Macro):\n",
        "    * Author's MultiResCNN model Metric: 0.9120\n",
        "    * Author's MultiResCNN with HiCuA Metric: 0.9470\n",
        "    * Claim 2 MultiResCNN Metric: **0.8983**\n",
        "    * Claim 2 MultiResCNN with HiCuA Metric: **0.9115**\n",
        "  * AUC (Micro):\n",
        "    * Author's MultiResCNN model Metric: 0.9870\n",
        "    * Author's MultiResCNN with HiCuA Metric: 0.9910\n",
        "    * Claim 2 MultiResCNN Metric: **0.9266**\n",
        "    * Claim 2 MultiResCNN with HiCuA Metric: **0.9324**\n",
        "  * Precision@8:\n",
        "    * Author's MultiResCNN model Metric: 0.7430\n",
        "    * Author's MultiResCNN with HiCuA Metric: 0.7480\n",
        "    * Claim 2 MultiResCNN Metric: **0.5095**\n",
        "    * Claim 2 MultiResCNN with HiCuA Metric: **0.5235**\n",
        "\n",
        "On average, Claim 2 produced results were 6-7% lower performance metrics over Authors' original HiCu algorithm.\n",
        "\n",
        "This indeed proves that the hypothesis \"Claim 2\" stands true: **Flatten 2-level heirarchy reduces model formance. Heirarchical learning approach is more efficient than non-heirarchical learning.**."
      ],
      "metadata": {
        "id": "2tkif1qd4ClH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Discussion**\n",
        "***\n",
        "#### **Implications of the experimental results, whether the original paper was reproducible, and if it wasn’t, what factors made it irreproducible**\n",
        "  * Original paper findings were reproducable to the extent I was able to build and run the models through scopes of both Claim 1 and Claim 2.\n",
        "  * However, at this point, I tested only MultiResCNN with and without HICUA, it is premature to conclusively declare the paper's reproducibility for all the referenced models. The initial results align with the paper's claims (as noted in the Results section), suggesting positive reproducibility indications. The ongoing experiments with RAC with HiCuA and LAAT with HiCuA and ASL will provide a comprehensive reproducibility verdict.\n",
        "\n",
        "\n",
        "#### **What was easy**\n",
        "  * Initial setup demanded few hours to determine the compatibility of software package versions (Python and other modules). With \"requirements.txt\" or \"environment.yml\" files, it would be easy building the environment for future projects.\n",
        "\n",
        "#### **What was difficult**\n",
        "  * Source data manuverability is touch since MIMIC-III is large.\n",
        "  * Availability of free/low-cost GPU and high-RAM environment was a challenge for me. I wish I had more time to explore other technology options to tackle this limitation. However, some Piazza posts helped garnering those ideas.\n",
        "  * The models' training are resource-intensive and time-consuming. It demanded substantial computational resources which limited the analysis time.\n",
        "  * High cost of powerful GPUs.\n",
        "  * Managing the project alone without referring with atleast another person is tough. Managing the challenges, overcoming the roadblocks, and still meeting the project deadline was a daunting task.\n",
        "  * **nltk** and **gensim** might be incompatible on some MAC architectures.\n",
        "  * **NOTEEVENTS.CSV** is a huge file (~4GB). Uploading this file was tough.\n",
        "  * Repeated disconnects at Google Colab made the session recovery impossible, leading to loss of effort and time.\n",
        "\n",
        "\n",
        "#### **Recommendations to the original authors or others who work in this area for improving reproducibility**\n",
        "  * Use a high power (RAM and GPU) local or cloud based computer to traing all the model in parallel. This will help getting all the .pth files. Then one can run performance comparison program components to analyze.\n",
        "  * Understand the software version compatibility upfront to save time.\n",
        "  * Start training with smaller / curated data to build the pipeline (both pre and post processing). Once the smaller set model is confirmed to be built successfully, then introduce large MIMIC-III datasets. This will save some front-load modeling time.\n",
        "  * Use 'environment.yml' file to easily setup modeling environment.\n",
        "  * Utilize cloud based pay-per-use hardware and services.\n",
        "  * Understand pre-requisites to setup inputs to preprocess and train the models. Based on my Python version, I had to make several code conversions from np.int to np.int32 and np.float to np.float32.\n",
        "  * Latest version of packages (**gensim, nltk, numpy, pandas, scikit-learn, scipy, torch, tqdm, transformers**)  are recommended and lookout for any functionality deprecation.\n",
        "  * Update command line parameters (**data_path, n_epochs, gpu, workers**) based on CPU/RAM configurations.\n",
        "  * For running all the 500+ iterations mentioned in the original paper, I would suggest to use **Google Cloud Platform** for training the models. **NVIDIA Tesla P100 GPU with CUDA** should be powerful enough to tackle the exhaustive and time-consuming model training process."
      ],
      "metadata": {
        "id": "ITKZc5-Wzdsq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Public GitHub Repo**\n",
        "***\n",
        "Public GitHub Repo: https://github.com/ratulsaha778/CS598-HiCu-Team26/\n",
        "\n",
        "README.md: https://github.com/ratulsaha778/CS598-HiCu-Team26/blob/main/README.md\n",
        "  \n",
        "  * **CS598-HiCu-Team26**: project folder\n",
        "    * **README.md**: read me file\n",
        "    * **main.py**: the master python program to run all the model variations.\n",
        "    * **preprocess_mimic3.py**: the python program for pre-processing MIMIC-III data\n",
        "    * **Team26_HiCu_Colab_Notebook_Draft.ipynb**: Python notebook for project draft\n",
        "    * **Team26_HiCu_Colab_Notebook_Draft.pdf**: PDF of project draft Python notebook\n",
        "    * **Team26_HiCu_Colab_Notebook_Final.ipynb**: Python notebook for final project (this document)\n",
        "    * **Team26_HiCu_Colab_Notebook_Draft.pdf**: PDF of project final Python notebook\n",
        "    * **data**: contains all source files\n",
        "        * **mimic3**: folder to contain pre-processed MIMIC-III needed to train the model\n",
        "        * **D_ICD_DIAGNOSES.csv**: diagnosis codes\n",
        "        * **D_ICD_PROCEDURES.csv**: procedure codes\n",
        "    * **presentation**: images, video presentation with link, powerpoint presentation.\n",
        "    * **runs**: python programs each with a different model variation (MultiResCNN, RAC and LAAT).\n",
        "    * **utils**: utility programs that are referenced throughout the project.\n",
        "    * **models**: pre-trained models, execution logs, performance metrics.\n"
      ],
      "metadata": {
        "id": "l76lOsrHzfLR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpxvAkx_EcNl"
      },
      "source": [
        "# **References**\n",
        "***\n",
        "* https://physionet.org/content/mimiciii/1.4/\n",
        "* https://github.com/wren93/HiCu-ICD/blob/main/README.md\n",
        "* https://github.com/foxlf823/Multi-Filter-Residual-Convolutional-Neural-Network\n",
        "* https://paperswithcode.com/paper/hicu-leveraging-hierarchy-for-curriculum\n",
        "* https://arxiv.org/abs/2208.02301\n",
        "* https://proceedings.mlr.press/v182/ren22a/ren22a.pdf\n",
        "* https://github.com/jamesmullenbach/caml-mimic/tree/master/mimicdata/mimic3\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}